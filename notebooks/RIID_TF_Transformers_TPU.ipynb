{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RIID TF Transformers TPU.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisarahamedk/kaggle-riid/blob/master/notebooks/RIID_TF_Transformers_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDcEKftRzz3o"
      },
      "source": [
        "#### RIID Transformer on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tXEAUsz-e0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.python.autograph.impl import api as autograph\n",
        "from tensorflow.python.autograph.core import ag_ctx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZwdiZXG0XgB"
      },
      "source": [
        "\n",
        "### *Device* Settings - This needs to be at the TOPÂ¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3giJ9Nu0aTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f498000-f49c-4d6c-80b0-7fddded950a3"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # no parameter needed for TPU_NAME env variable is set. This is the case for Kaggle\n",
        "    print(\"Running on TPU: \", tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU:  grpc://10.51.21.218:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8cViVXg0dRt",
        "outputId": "0954b9d7-e811-4980-cc49-ea2c79027d3e"
      },
      "source": [
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # default strategy with the available hw\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    \n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(\"REPLICAS: \", REPLICAS)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.21.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.21.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHATf5SI0f7k"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZyQj3J-0sCh"
      },
      "source": [
        "DATA_PATH = 'gs://kds-0d2ffe2dbc91ac5f57c8846e2d8c3ef3f2c48c5e264ae5abb3f92918'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNldoAXn1GOf",
        "outputId": "114362c0-d078-4f38-b0d9-dc341fd5a305"
      },
      "source": [
        "n_train_files = len(tf.io.gfile.glob(DATA_PATH + \"/tfrec*\"))\n",
        "n_train_files"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KLXao8j1jSp",
        "outputId": "70e3e31f-1b3a-4df0-dea7-58f419e1d224"
      },
      "source": [
        "FOLDS = 10\n",
        "\n",
        "kfold = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "folds_list = list(kfold.split(np.arange(n_train_files)))\n",
        "folds_list[:2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 18,\n",
              "         19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31]),\n",
              "  array([15, 17, 24, 29])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
              "         19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31]),\n",
              "  array([ 8,  9, 25, 30]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC8RRFAM11rq",
        "outputId": "1717fe55-1c16-4ecd-c05b-3641336ccd91"
      },
      "source": [
        "FOLD = 5\n",
        "\n",
        "train_folds, valid_folds = folds_list[FOLD]\n",
        "len(train_folds), len(valid_folds)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztufELqg2Xfn"
      },
      "source": [
        "train_files = tf.io.gfile.glob([DATA_PATH + \"/tfrec_%d.tfrec\" % idx for idx in train_folds])\n",
        "valid_files = tf.io.gfile.glob([DATA_PATH + \"/tfrec_%d.tfrec\" % idx for idx in valid_folds])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6yVysK22E6",
        "outputId": "3a717a6e-f51f-4bb4-a2f0-6bc013fa742c"
      },
      "source": [
        "len(train_files), len(valid_files)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHpRgO2L25aj"
      },
      "source": [
        "#### Load TFRecord Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0zEw3u23jmr"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXHOsZ13sEX"
      },
      "source": [
        "feature_desc = {\n",
        "    \"content_id\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"task_container_id\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"prior_question_elapsed_time\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"part\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"prev_answered_correctly\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"answered_correctly\": tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def parse_example(example):\n",
        "  example = tf.io.parse_single_example(example, feature_desc)\n",
        "\n",
        "  content_id = tf.io.parse_tensor(example[\"content_id\"], tf.int16)\n",
        "  task_container_id = tf.io.parse_tensor(example[\"task_container_id\"], tf.int16)\n",
        "  prior_question_elapsed_time = tf.io.parse_tensor(example[\"prior_question_elapsed_time\"], tf.float32)\n",
        "  part = tf.io.parse_tensor(example[\"part\"], tf.int16)\n",
        "  prev_answered_correctly = tf.io.parse_tensor(example[\"prev_answered_correctly\"], tf.int8)\n",
        "  answered_correctly = tf.io.parse_tensor(example[\"answered_correctly\"], tf.int8)\n",
        "  \n",
        "  return tf.stack([\n",
        "      tf.cast(content_id, tf.float32),\n",
        "      tf.cast(task_container_id, tf.float32),\n",
        "      tf.cast(prior_question_elapsed_time, tf.float32),\n",
        "      tf.cast(part, tf.float32),\n",
        "      tf.cast(prev_answered_correctly, tf.float32),\n",
        "      tf.cast(answered_correctly, tf.float32)\n",
        "  ]) # [features, seq_len] # TODO make it [seq_len, features] so that we dont have to reshape in transformer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vZigwi3QVa"
      },
      "source": [
        "def load_dataset_from_tfrecord(filenames, ds_type=\"train\", cache_to=None):\n",
        "        # Since we are reading dataset from multiple files. and we dont care about the order.\n",
        "        # set deterministic reading to False.\n",
        "        ignore_order = tf.data.Options()\n",
        "        if ds_type == \"train\":\n",
        "            ignore_order.experimental_deterministic = False\n",
        "            \n",
        "        dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "        if not cache_to:\n",
        "            dataset = dataset.cache() # cache to RAM\n",
        "        else:\n",
        "            dataset = dataset.cache(cache_to) # cache to file given by self.cache_to \n",
        "        if ds_type == \"train\":\n",
        "            # dataset = dataset.repeat() # repeat individual item, so that we have full batch at every step.\n",
        "            pass\n",
        "        dataset.with_options(ignore_order)\n",
        "        dataset = dataset.map(parse_example, num_parallel_calls=AUTOTUNE)\n",
        "        return dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhaJdlb537yQ"
      },
      "source": [
        "dataset = load_dataset_from_tfrecord(train_files)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JPG7fOy4jCu"
      },
      "source": [
        "SEQ_LEN = 128"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4QnfOgm4FWT"
      },
      "source": [
        "@tf.function\n",
        "def pad(a, seq_len, max_seq_len):\n",
        "  s = max_seq_len - seq_len\n",
        "  # making [[0, 0], [s, 0]]\n",
        "  r = tf.stack([s, tf.constant(0)])\n",
        "  t = tf.stack([tf.constant([0, 0]), r])\n",
        "  \n",
        "  return tf.pad(a, t) # ,1 to debug\n",
        "\n",
        "@tf.function\n",
        "def trim(a, seq_len,  max_seq_len):\n",
        "  start = tf.squeeze(tf.random.uniform((1,), maxval=(seq_len-max_seq_len), dtype=tf.int32))\n",
        "  # https://www.quora.com/How-does-tf-slice-work-in-TensorFlow\n",
        "  begin = tf.stack([tf.constant(0), start])\n",
        "  size = tf.stack([tf.shape(a)[0], max_seq_len])\n",
        "  \n",
        "  return tf.slice(a, begin, size) # , start - to debug\n",
        "\n",
        "@tf.function\n",
        "def pad_or_trim(a):\n",
        "  seq_len = tf.shape(a)[-1]\n",
        "  max_seq_len = SEQ_LEN\n",
        "  fn = tf.cond(tf.less_equal(seq_len, max_seq_len), lambda: pad(a, seq_len, max_seq_len), lambda: trim(a, seq_len, max_seq_len))\n",
        "  return fn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi2ty0Rd4kyp"
      },
      "source": [
        "dataset = dataset.map(pad_or_trim, num_parallel_calls=AUTOTUNE) # every sample is padded if len < SEQ_LEN or randomly trimmed to SEQ_LEN"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOTG_iFxa5gc"
      },
      "source": [
        "@tf.function\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.reduce_all(tf.math.equal(seq, 0), axis=-1), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "@tf.function\n",
        "def split_x_y_mask(xy):\n",
        "  x = xy[:-1, :]\n",
        "  x = tf.transpose(x, (1, 0)) # [seq_len, n_features]\n",
        "  y = xy[-1, :]\n",
        "  pad_mask = tf.cast(tf.math.reduce_any(tf.math.not_equal(x, 0), axis=-1), dtype=tf.float32)\n",
        "  return x, tf.expand_dims(y, axis=-1), tf.expand_dims(pad_mask, axis=-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_CI26N0K3R6"
      },
      "source": [
        "dataset = dataset.map(split_x_y_mask) # x and y"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5eT_hwk4qaY",
        "outputId": "88696e5a-5eef-48b9-84d7-de8fa02cd374"
      },
      "source": [
        "for x, y, pad_mask in dataset.take(1):\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(pad_mask.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 5)\n",
            "(128, 1)\n",
            "(128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0Jw9j1hxTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75eaaf20-3306-41ca-e1a2-725ecb3e5319"
      },
      "source": [
        "tf.squeeze(pad_mask, axis=-1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE8uOJbx2W2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2d91f1-19e9-405b-d93f-f1a34d99f67f"
      },
      "source": [
        "tf.squeeze(y, axis=-1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVuc7KqWFZ01"
      },
      "source": [
        "dataset = dataset.shuffle(int(1024 * REPLICAS))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3iCpAnFvIL"
      },
      "source": [
        "BATCH_SIZE = 256"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8zSQyaFzLV"
      },
      "source": [
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMQdN2zgF9hw",
        "outputId": "40062f04-9c20-462f-ebbe-a40dc5be1f7d"
      },
      "source": [
        "for xb, yb, mb in dataset.take(1):\n",
        "  print(xb.shape)\n",
        "  print(yb.shape)\n",
        "  print(mb.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 128, 5)\n",
            "(256, 128, 1)\n",
            "(256, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpW8ID94dPC",
        "outputId": "26b6f52f-3cb4-4cc8-8c97-c925db0c93f7"
      },
      "source": [
        "# prev_answered_feature\n",
        "xb[0, :, -1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 2., 1., 1.,\n",
              "       2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
              "       1., 1., 2., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S33r8rmn4kdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd860f8c-61fd-4ff8-984c-321268b19078"
      },
      "source": [
        "# corresponding mask\n",
        "mb[0, :, 0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbmVLJKDGBYX"
      },
      "source": [
        "dataset = dataset.prefetch(AUTOTUNE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIKTPaHerpwF"
      },
      "source": [
        "Valid dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCL1p1-uruwd"
      },
      "source": [
        "valid_dataset = load_dataset_from_tfrecord(valid_files, ds_type=\"valid\")\n",
        "valid_dataset = valid_dataset.map(pad_or_trim, num_parallel_calls=AUTOTUNE) # every sample is padded if len < SEQ_LEN or randomly trimmed to SEQ_LEN\n",
        "valid_dataset = valid_dataset.map(split_x_y_mask) # x and y\n",
        "valid_dataset = valid_dataset.batch(BATCH_SIZE * 2)\n",
        "valid_dataset = valid_dataset.prefetch(AUTOTUNE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FYgAeXTLsu5"
      },
      "source": [
        "# len(list(iter(dataset.take(1000)))) # dataset repeats indefinitely"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7N2qkPoGF8n"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzidzjELLqY7"
      },
      "source": [
        "##### Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3OWpbddMhgh"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA17TuuTMh8R"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pROxdYkMkRi"
      },
      "source": [
        "##### Look ahead mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3ZVSk3oMxg3"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfDhTLswMyDl"
      },
      "source": [
        "##### Scaled Dot Product Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJhA4M7XM8zY"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak8Y8-ihNG1j"
      },
      "source": [
        "##### Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkL0KZ5uNMS7"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwQteAZBNPtG"
      },
      "source": [
        "##### Pointwise FeedForward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiYVEX_0NX54"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGbRm0LSNau_"
      },
      "source": [
        "##### EncoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96wCZDvNexl"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7i7zR9xNjMj"
      },
      "source": [
        "##### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM4bREj9Nrp_"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.content_id_emb = tf.keras.layers.Embedding(embed_size_dict[\"content_id\"] + 1, d_model)\n",
        "    self.task_container_id_emb = tf.keras.layers.Embedding(embed_size_dict[\"task_container_id\"] + 1, d_model)\n",
        "    self.part_emb = tf.keras.layers.Embedding(embed_size_dict[\"part\"] + 2, d_model)\n",
        "    self.prior_question_elapsed_time_emb = tf.keras.layers.Dense(d_model, use_bias=True)\n",
        "    self.prev_answered_emb = tf.keras.layers.Embedding(4, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embeddings and position encoding.\n",
        "    c_emb = self.content_id_emb(x[..., 0])  # (batch_size, input_seq_len, d_model)\n",
        "    t_emb = self.task_container_id_emb(x[..., 1])\n",
        "    prior_time_emb = self.prior_question_elapsed_time_emb(tf.expand_dims(x[..., 2], axis=-1))\n",
        "    pt_emb = self.part_emb(x[..., 3])\n",
        "    pv_emb = self.prev_answered_emb(x[..., 4])\n",
        "    x = c_emb + t_emb + prior_time_emb + pt_emb + pv_emb\n",
        "    \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask) # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PcxHfXTp64m"
      },
      "source": [
        "class TransformerSeq2SeqClassifier(keras.models.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate=0.1):\n",
        "    super(TransformerSeq2SeqClassifier, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate)\n",
        "    self.out = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "  def call(self, x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "    encoded = self.encoder(x, mask=look_ahead_mask)\n",
        "\n",
        "    out = self.out(encoded)\n",
        "    return out # [batch_size, input_seq_len, 1]\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFiVa3cKN4E_"
      },
      "source": [
        "###### Embedding Sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xU0IaYQX_XG"
      },
      "source": [
        "embed_sizes = pickle.loads(tf.io.read_file(DATA_PATH + \"/emb_sz.pkl\").numpy())"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfN7FrvjY02x",
        "outputId": "f6575765-c107-405e-a804-d4d66b5e7e3e"
      },
      "source": [
        "embed_sizes"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'content_id': 32736, 'part': 7, 'task_container_id': 9999}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWvXJsP3Y2Bt"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = TransformerSeq2SeqClassifier(\n",
        "      num_layers=1,\n",
        "      d_model=512,\n",
        "      num_heads=8,\n",
        "      dff=1024,\n",
        "      maximum_position_encoding=128,\n",
        "      embed_size_dict=embed_sizes\n",
        "  )"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "givnKZG-ar9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d694ac0-4b88-4c72-cdfe-5ed460948cf2"
      },
      "source": [
        "for xb, yb, mb in dataset.take(1):\n",
        "  print(xb.shape, yb.shape, mb.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 128, 5) (256, 128, 1) (256, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubeynQDIa3V_"
      },
      "source": [
        "# with strategy.scope():\r\n",
        "#   y_pred = model(xb)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcWnSd8TpiZi"
      },
      "source": [
        "class CustomAUC(keras.metrics.Metric):\r\n",
        "\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "\r\n",
        "    self.auc = keras.metrics.AUC()\r\n",
        "\r\n",
        "  def update_state(self, y_true, y_pred, sample_weight):\r\n",
        "\r\n",
        "    self.auc.update_state(y_true, y_pred, sample_weight)\r\n",
        "\r\n",
        "  def result(self):\r\n",
        "    return self.auc.result()\r\n",
        "\r\n",
        "  def reset_states(self):\r\n",
        "    return self.auc.reset_states()\r\n",
        "\r\n",
        "  def get_config(self):\r\n",
        "    return self.auc.get_config()\r\n",
        "\r\n",
        "  @property\r\n",
        "  def thresholds(self):\r\n",
        "    return self.auc.thresholds"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCYG-IobCINv"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvlTpfOyxEHa"
      },
      "source": [
        "class MaskedBCELoss(keras.losses.Loss):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "\r\n",
        "    self.bce = keras.losses.BinaryCrossentropy(reduction=keras.losses.Reduction.NONE)\r\n",
        "\r\n",
        "  def call(self, y_true, y_pred, sample_weight):\r\n",
        "\r\n",
        "    normal_bce_loss = self.bce(y_true, y_pred, sample_weight) # gives 0 where masked.\r\n",
        "\r\n",
        "    # count # of non masked entries in the batch\r\n",
        "    unmasked_count = tf.math.reduce_sum(tf.cast(tf.math.not_equal(normal_bce_loss, 0), tf.float32))\r\n",
        "\r\n",
        "    # sum the unmasked entries.\r\n",
        "    unmasked_sum = tf.math.reduce_sum(normal_bce_loss)\r\n",
        "  \r\n",
        "    average_loss = tf.math.divide(unmasked_sum, unmasked_count)\r\n",
        "\r\n",
        "    return average_loss\r\n",
        "\r\n",
        "  def __call__(self, y_true, y_pred, sample_weight):\r\n",
        "\r\n",
        "    graph_ctx = tf_utils.graph_context_for_symbolic_tensors(\r\n",
        "        y_true, y_pred, sample_weight)\r\n",
        "    with K.name_scope(self._name_scope), graph_ctx:\r\n",
        "      ag_call = autograph.tf_convert(self.call, ag_ctx.control_status_ctx())\r\n",
        "      losses = ag_call(y_true, y_pred, sample_weight)\r\n",
        "      return losses\r\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Q_LtMP58mr"
      },
      "source": [
        "# loss = MaskedBCELoss()\r\n",
        "# loss(yb, y_pred, mb)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOhUhp9OmsjJ"
      },
      "source": [
        "with strategy.scope():\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=3e-5)\n",
        "  # loss = keras.losses.BinaryCrossentropy()\n",
        "  loss = MaskedBCELoss()\n",
        "  reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=4, min_lr=1e-7, verbose=1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo7o34xVoeFc"
      },
      "source": [
        "with strategy.scope():\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics=[CustomAUC()]) #, weighted_metrics=[CustomAUC()]) # \"weighted_metrics\" not supported on TPU with tf.data"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpViganz2pH"
      },
      "source": [
        "# ## OVERFIT SINGLE BATCH\n",
        "# with strategy.scope():\n",
        "#   x, y, mask = next(iter(dataset.take(1))) # cannot just use take(), cause that return different batch everytime\n",
        "#   print(x.shape, y.shape, mask.shape)\n",
        "#   model.fit(x, y, epochs=100, sample_weight=mask, callbacks=[reduce_lr_cb])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Lfz06ApMcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4915e1-cad0-4ad8-cdb7-d8cc94be07bb"
      },
      "source": [
        "with strategy.scope():\n",
        "  history = model.fit(dataset, validation_data=valid_dataset, epochs=10, callbacks=[reduce_lr_cb])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1394/1394 [==============================] - 76s 55ms/step - loss: 0.6025 - custom_auc: 0.7630 - val_loss: nan - val_custom_auc: 0.7952\n",
            "Epoch 2/100\n",
            "1394/1394 [==============================] - 65s 47ms/step - loss: 0.5764 - custom_auc: 0.7882 - val_loss: nan - val_custom_auc: 0.7677\n",
            "Epoch 3/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5721 - custom_auc: 0.7492 - val_loss: nan - val_custom_auc: 0.7260\n",
            "Epoch 4/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5700 - custom_auc: 0.7463 - val_loss: nan - val_custom_auc: 0.7533\n",
            "Epoch 5/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5681 - custom_auc: 0.7520 - val_loss: nan - val_custom_auc: 0.7607\n",
            "Epoch 6/100\n",
            "1394/1394 [==============================] - 65s 47ms/step - loss: 0.5668 - custom_auc: 0.7857 - val_loss: nan - val_custom_auc: 0.7909\n",
            "Epoch 7/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5660 - custom_auc: 0.8178 - val_loss: nan - val_custom_auc: 0.8121\n",
            "Epoch 8/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5649 - custom_auc: 0.8391 - val_loss: nan - val_custom_auc: 0.8538\n",
            "Epoch 9/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5632 - custom_auc: 0.8620 - val_loss: nan - val_custom_auc: 0.8479\n",
            "Epoch 10/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5626 - custom_auc: 0.8657 - val_loss: nan - val_custom_auc: 0.8716\n",
            "Epoch 11/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5616 - custom_auc: 0.8625 - val_loss: nan - val_custom_auc: 0.8593\n",
            "Epoch 12/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5611 - custom_auc: 0.8530 - val_loss: nan - val_custom_auc: 0.8550\n",
            "Epoch 13/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5596 - custom_auc: 0.8513 - val_loss: nan - val_custom_auc: 0.8450\n",
            "Epoch 14/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5593 - custom_auc: 0.8450 - val_loss: nan - val_custom_auc: 0.8335\n",
            "Epoch 15/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5586 - custom_auc: 0.8377 - val_loss: nan - val_custom_auc: 0.8490\n",
            "Epoch 16/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5574 - custom_auc: 0.8408 - val_loss: nan - val_custom_auc: 0.8357\n",
            "Epoch 17/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5567 - custom_auc: 0.8402 - val_loss: nan - val_custom_auc: 0.8311\n",
            "Epoch 18/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5554 - custom_auc: 0.8306 - val_loss: nan - val_custom_auc: 0.8153\n",
            "Epoch 19/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5544 - custom_auc: 0.8159 - val_loss: nan - val_custom_auc: 0.8198\n",
            "Epoch 20/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5532 - custom_auc: 0.8235 - val_loss: nan - val_custom_auc: 0.8177\n",
            "Epoch 21/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5524 - custom_auc: 0.8195 - val_loss: nan - val_custom_auc: 0.8098\n",
            "Epoch 22/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5512 - custom_auc: 0.8195 - val_loss: nan - val_custom_auc: 0.8153\n",
            "Epoch 23/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5502 - custom_auc: 0.8257 - val_loss: nan - val_custom_auc: 0.7988\n",
            "Epoch 24/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5487 - custom_auc: 0.8201 - val_loss: nan - val_custom_auc: 0.8182\n",
            "Epoch 25/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5475 - custom_auc: 0.8274 - val_loss: nan - val_custom_auc: 0.8267\n",
            "Epoch 26/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5464 - custom_auc: 0.8312 - val_loss: nan - val_custom_auc: 0.8150\n",
            "Epoch 27/100\n",
            "1394/1394 [==============================] - 68s 49ms/step - loss: 0.5453 - custom_auc: 0.8268 - val_loss: nan - val_custom_auc: 0.7922\n",
            "Epoch 28/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5441 - custom_auc: 0.8270 - val_loss: nan - val_custom_auc: 0.8265\n",
            "Epoch 29/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5430 - custom_auc: 0.8227 - val_loss: nan - val_custom_auc: 0.8215\n",
            "Epoch 30/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5415 - custom_auc: 0.8257 - val_loss: nan - val_custom_auc: 0.8127\n",
            "Epoch 31/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5402 - custom_auc: 0.8238 - val_loss: nan - val_custom_auc: 0.8064\n",
            "Epoch 32/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5396 - custom_auc: 0.8190 - val_loss: nan - val_custom_auc: 0.8216\n",
            "Epoch 33/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5378 - custom_auc: 0.8299 - val_loss: nan - val_custom_auc: 0.8247\n",
            "Epoch 34/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5367 - custom_auc: 0.8257 - val_loss: nan - val_custom_auc: 0.8078\n",
            "Epoch 35/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5356 - custom_auc: 0.8265 - val_loss: nan - val_custom_auc: 0.7979\n",
            "Epoch 36/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5343 - custom_auc: 0.8243 - val_loss: nan - val_custom_auc: 0.7911\n",
            "Epoch 37/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5333 - custom_auc: 0.8166 - val_loss: nan - val_custom_auc: 0.8153\n",
            "Epoch 38/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5325 - custom_auc: 0.8278 - val_loss: nan - val_custom_auc: 0.8175\n",
            "Epoch 39/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5313 - custom_auc: 0.8191 - val_loss: nan - val_custom_auc: 0.8124\n",
            "Epoch 40/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5315 - custom_auc: 0.8256 - val_loss: nan - val_custom_auc: 0.8010\n",
            "Epoch 41/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5305 - custom_auc: 0.8282 - val_loss: nan - val_custom_auc: 0.7960\n",
            "Epoch 42/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5284 - custom_auc: 0.8204 - val_loss: nan - val_custom_auc: 0.7984\n",
            "Epoch 43/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5273 - custom_auc: 0.8220 - val_loss: nan - val_custom_auc: 0.8020\n",
            "Epoch 44/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5264 - custom_auc: 0.8197 - val_loss: nan - val_custom_auc: 0.7891\n",
            "Epoch 45/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.5261 - custom_auc: 0.8155 - val_loss: nan - val_custom_auc: 0.7835\n",
            "Epoch 46/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5268 - custom_auc: 0.8156 - val_loss: nan - val_custom_auc: 0.7782\n",
            "Epoch 47/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5242 - custom_auc: 0.8072 - val_loss: nan - val_custom_auc: 0.7694\n",
            "Epoch 48/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5231 - custom_auc: 0.8081 - val_loss: nan - val_custom_auc: 0.8039\n",
            "Epoch 49/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5225 - custom_auc: 0.8127 - val_loss: nan - val_custom_auc: 0.7663\n",
            "Epoch 50/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5211 - custom_auc: 0.8085 - val_loss: nan - val_custom_auc: 0.7612\n",
            "Epoch 51/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5205 - custom_auc: 0.8021 - val_loss: nan - val_custom_auc: 0.7699\n",
            "Epoch 52/100\n",
            "1394/1394 [==============================] - 68s 49ms/step - loss: 0.5194 - custom_auc: 0.8071 - val_loss: nan - val_custom_auc: 0.7985\n",
            "Epoch 53/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5185 - custom_auc: 0.8156 - val_loss: nan - val_custom_auc: 0.7684\n",
            "Epoch 54/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5169 - custom_auc: 0.8118 - val_loss: nan - val_custom_auc: 0.7987\n",
            "Epoch 55/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5160 - custom_auc: 0.8134 - val_loss: nan - val_custom_auc: 0.8039\n",
            "Epoch 56/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5170 - custom_auc: 0.8183 - val_loss: nan - val_custom_auc: 0.7843\n",
            "Epoch 57/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5169 - custom_auc: 0.8182 - val_loss: nan - val_custom_auc: 0.7630\n",
            "Epoch 58/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5152 - custom_auc: 0.8140 - val_loss: nan - val_custom_auc: 0.7606\n",
            "Epoch 59/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5139 - custom_auc: 0.8097 - val_loss: nan - val_custom_auc: 0.7644\n",
            "Epoch 60/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5128 - custom_auc: 0.8042 - val_loss: nan - val_custom_auc: 0.7552\n",
            "Epoch 61/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5113 - custom_auc: 0.8087 - val_loss: nan - val_custom_auc: 0.7554\n",
            "Epoch 62/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5134 - custom_auc: 0.8090 - val_loss: nan - val_custom_auc: 0.7333\n",
            "Epoch 63/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5114 - custom_auc: 0.8027 - val_loss: nan - val_custom_auc: 0.7259\n",
            "Epoch 64/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5116 - custom_auc: 0.8026 - val_loss: nan - val_custom_auc: 0.7513\n",
            "Epoch 65/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5095 - custom_auc: 0.7954 - val_loss: nan - val_custom_auc: 0.7552\n",
            "Epoch 66/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5080 - custom_auc: 0.8050 - val_loss: nan - val_custom_auc: 0.7749\n",
            "Epoch 67/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5070 - custom_auc: 0.8044 - val_loss: nan - val_custom_auc: 0.7511\n",
            "Epoch 68/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5058 - custom_auc: 0.8089 - val_loss: nan - val_custom_auc: 0.7673\n",
            "Epoch 69/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5051 - custom_auc: 0.8088 - val_loss: nan - val_custom_auc: 0.7641\n",
            "Epoch 70/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5040 - custom_auc: 0.8105 - val_loss: nan - val_custom_auc: 0.7720\n",
            "Epoch 71/100\n",
            "1394/1394 [==============================] - 65s 47ms/step - loss: 0.5032 - custom_auc: 0.8126 - val_loss: nan - val_custom_auc: 0.7767\n",
            "Epoch 72/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.5034 - custom_auc: 0.8059 - val_loss: nan - val_custom_auc: 0.7556\n",
            "Epoch 73/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5019 - custom_auc: 0.8084 - val_loss: nan - val_custom_auc: 0.7178\n",
            "Epoch 74/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.5014 - custom_auc: 0.8025 - val_loss: nan - val_custom_auc: 0.7464\n",
            "Epoch 75/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.5009 - custom_auc: 0.8029 - val_loss: nan - val_custom_auc: 0.7444\n",
            "Epoch 76/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.4996 - custom_auc: 0.8060 - val_loss: nan - val_custom_auc: 0.7693\n",
            "Epoch 77/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.4993 - custom_auc: 0.8036 - val_loss: nan - val_custom_auc: 0.7546\n",
            "Epoch 78/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.4985 - custom_auc: 0.8013 - val_loss: nan - val_custom_auc: 0.7134\n",
            "Epoch 79/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.4978 - custom_auc: 0.7971 - val_loss: nan - val_custom_auc: 0.7348\n",
            "Epoch 80/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.4969 - custom_auc: 0.8025 - val_loss: nan - val_custom_auc: 0.7143\n",
            "Epoch 81/100\n",
            "1394/1394 [==============================] - 65s 47ms/step - loss: 0.4966 - custom_auc: 0.7996 - val_loss: nan - val_custom_auc: 0.7078\n",
            "Epoch 82/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4969 - custom_auc: 0.7887 - val_loss: nan - val_custom_auc: 0.7435\n",
            "Epoch 83/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4950 - custom_auc: 0.7947 - val_loss: nan - val_custom_auc: 0.7359\n",
            "Epoch 84/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.4961 - custom_auc: 0.7972 - val_loss: nan - val_custom_auc: 0.7276\n",
            "Epoch 85/100\n",
            "1394/1394 [==============================] - 66s 48ms/step - loss: 0.4943 - custom_auc: 0.7869 - val_loss: nan - val_custom_auc: 0.7128\n",
            "Epoch 86/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4931 - custom_auc: 0.7917 - val_loss: nan - val_custom_auc: 0.7231\n",
            "Epoch 87/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4945 - custom_auc: 0.7983 - val_loss: nan - val_custom_auc: 0.6801\n",
            "Epoch 88/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4922 - custom_auc: 0.7919 - val_loss: nan - val_custom_auc: 0.7100\n",
            "Epoch 89/100\n",
            "1394/1394 [==============================] - 68s 49ms/step - loss: 0.4915 - custom_auc: 0.7950 - val_loss: nan - val_custom_auc: 0.7429\n",
            "Epoch 90/100\n",
            "1394/1394 [==============================] - 68s 49ms/step - loss: 0.4905 - custom_auc: 0.7938 - val_loss: nan - val_custom_auc: 0.7172\n",
            "Epoch 91/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.4929 - custom_auc: 0.7976 - val_loss: nan - val_custom_auc: 0.6595\n",
            "Epoch 92/100\n",
            "1394/1394 [==============================] - 68s 48ms/step - loss: 0.4910 - custom_auc: 0.7998 - val_loss: nan - val_custom_auc: 0.7142\n",
            "Epoch 93/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4896 - custom_auc: 0.7998 - val_loss: nan - val_custom_auc: 0.7362\n",
            "Epoch 94/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4887 - custom_auc: 0.8039 - val_loss: nan - val_custom_auc: 0.7078\n",
            "Epoch 95/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4878 - custom_auc: 0.8005 - val_loss: nan - val_custom_auc: 0.7498\n",
            "Epoch 96/100\n",
            "1394/1394 [==============================] - 66s 47ms/step - loss: 0.4903 - custom_auc: 0.8046 - val_loss: nan - val_custom_auc: 0.7022\n",
            "Epoch 97/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4875 - custom_auc: 0.7919 - val_loss: nan - val_custom_auc: 0.7042\n",
            "Epoch 98/100\n",
            "1394/1394 [==============================] - 68s 49ms/step - loss: 0.4865 - custom_auc: 0.7956 - val_loss: nan - val_custom_auc: 0.7007\n",
            "Epoch 99/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4858 - custom_auc: 0.7962 - val_loss: nan - val_custom_auc: 0.7088\n",
            "Epoch 100/100\n",
            "1394/1394 [==============================] - 67s 48ms/step - loss: 0.4848 - custom_auc: 0.7989 - val_loss: nan - val_custom_auc: 0.7094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaEXkjV2wfB9"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW2RThBsNqLK"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  metric = keras.metrics.AUC()\r\n",
        "\r\n",
        "  for valid_xb, valid_yb, valid_mb in valid_dataset:\r\n",
        "    valid_y_pred = model.predict(valid_xb)\r\n",
        "    metric.update_state(valid_yb, valid_y_pred, valid_mb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECZMJ3PuNsc3"
      },
      "source": [
        "metric.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}