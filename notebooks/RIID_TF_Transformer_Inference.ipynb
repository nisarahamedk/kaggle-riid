{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.025963,
     "end_time": "2020-12-20T09:25:09.650758",
     "exception": false,
     "start_time": "2020-12-20T09:25:09.624795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nisarahamedk/kaggle-riid/blob/master/notebooks/RIID_TF_Transformer_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIIMFhdG1L1o",
    "papermill": {
     "duration": 0.024518,
     "end_time": "2020-12-20T09:25:09.700150",
     "exception": false,
     "start_time": "2020-12-20T09:25:09.675632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### RIID TF Transformer Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:09.757828Z",
     "iopub.status.busy": "2020-12-20T09:25:09.756825Z",
     "iopub.status.idle": "2020-12-20T09:25:16.353233Z",
     "shell.execute_reply": "2020-12-20T09:25:16.352511Z"
    },
    "id": "KyaJuEug1SjH",
    "papermill": {
     "duration": 6.628939,
     "end_time": "2020-12-20T09:25:16.353356",
     "exception": false,
     "start_time": "2020-12-20T09:25:09.724417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.406609Z",
     "iopub.status.busy": "2020-12-20T09:25:16.405539Z",
     "iopub.status.idle": "2020-12-20T09:25:16.409947Z",
     "shell.execute_reply": "2020-12-20T09:25:16.410544Z"
    },
    "id": "djh3Uu2t5gW0",
    "papermill": {
     "duration": 0.03262,
     "end_time": "2020-12-20T09:25:16.410702",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.378082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqfXTHol5tsO",
    "papermill": {
     "duration": 0.024619,
     "end_time": "2020-12-20T09:25:16.459669",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.435050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Etv2NO5zT2",
    "papermill": {
     "duration": 0.024094,
     "end_time": "2020-12-20T09:25:16.509719",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.485625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.563746Z",
     "iopub.status.busy": "2020-12-20T09:25:16.562660Z",
     "iopub.status.idle": "2020-12-20T09:25:16.568002Z",
     "shell.execute_reply": "2020-12-20T09:25:16.568508Z"
    },
    "id": "n6vaouEE53Ht",
    "papermill": {
     "duration": 0.034041,
     "end_time": "2020-12-20T09:25:16.568658",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.534617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.623059Z",
     "iopub.status.busy": "2020-12-20T09:25:16.622017Z",
     "iopub.status.idle": "2020-12-20T09:25:16.630169Z",
     "shell.execute_reply": "2020-12-20T09:25:16.630711Z"
    },
    "id": "xxFYxFOo55M1",
    "papermill": {
     "duration": 0.037478,
     "end_time": "2020-12-20T09:25:16.630866",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.593388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZbzX60E58BU",
    "papermill": {
     "duration": 0.02465,
     "end_time": "2020-12-20T09:25:16.680591",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.655941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Look ahead maskÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.734974Z",
     "iopub.status.busy": "2020-12-20T09:25:16.733883Z",
     "iopub.status.idle": "2020-12-20T09:25:16.739368Z",
     "shell.execute_reply": "2020-12-20T09:25:16.739897Z"
    },
    "id": "zPGr-jHm5---",
    "papermill": {
     "duration": 0.034448,
     "end_time": "2020-12-20T09:25:16.740060",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.705612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEG9-yfd6B4z",
    "papermill": {
     "duration": 0.025375,
     "end_time": "2020-12-20T09:25:16.790892",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.765517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.847010Z",
     "iopub.status.busy": "2020-12-20T09:25:16.845951Z",
     "iopub.status.idle": "2020-12-20T09:25:16.855212Z",
     "shell.execute_reply": "2020-12-20T09:25:16.855751Z"
    },
    "id": "YJQ-2NrS6FNc",
    "papermill": {
     "duration": 0.0392,
     "end_time": "2020-12-20T09:25:16.855896",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.816696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRn4GRyP6H19",
    "papermill": {
     "duration": 0.02489,
     "end_time": "2020-12-20T09:25:16.905881",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.880991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:16.977239Z",
     "iopub.status.busy": "2020-12-20T09:25:16.976096Z",
     "iopub.status.idle": "2020-12-20T09:25:16.982949Z",
     "shell.execute_reply": "2020-12-20T09:25:16.982268Z"
    },
    "id": "gxrdILh26KPP",
    "papermill": {
     "duration": 0.047728,
     "end_time": "2020-12-20T09:25:16.983073",
     "exception": false,
     "start_time": "2020-12-20T09:25:16.935345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8iz9DQL61_Q",
    "papermill": {
     "duration": 0.025689,
     "end_time": "2020-12-20T09:25:17.034254",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.008565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Pointwise FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.092359Z",
     "iopub.status.busy": "2020-12-20T09:25:17.091234Z",
     "iopub.status.idle": "2020-12-20T09:25:17.094850Z",
     "shell.execute_reply": "2020-12-20T09:25:17.094285Z"
    },
    "id": "jP7TSLvH65Ag",
    "papermill": {
     "duration": 0.035266,
     "end_time": "2020-12-20T09:25:17.094969",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.059703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeudaHGQ67H6",
    "papermill": {
     "duration": 0.025413,
     "end_time": "2020-12-20T09:25:17.146262",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.120849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.200582Z",
     "iopub.status.busy": "2020-12-20T09:25:17.199914Z",
     "iopub.status.idle": "2020-12-20T09:25:17.211181Z",
     "shell.execute_reply": "2020-12-20T09:25:17.211738Z"
    },
    "id": "5bcO_5Y-6-oi",
    "papermill": {
     "duration": 0.040089,
     "end_time": "2020-12-20T09:25:17.211909",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.171820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbPkooHe7BRD",
    "papermill": {
     "duration": 0.025512,
     "end_time": "2020-12-20T09:25:17.263108",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.237596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.318034Z",
     "iopub.status.busy": "2020-12-20T09:25:17.317351Z",
     "iopub.status.idle": "2020-12-20T09:25:17.336096Z",
     "shell.execute_reply": "2020-12-20T09:25:17.335532Z"
    },
    "id": "cGUaKNGc7Dy8",
    "papermill": {
     "duration": 0.04752,
     "end_time": "2020-12-20T09:25:17.336246",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.288726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.content_id_emb = tf.keras.layers.Embedding(embed_size_dict[\"content_id\"] + 1, d_model)\n",
    "    self.task_container_id_emb = tf.keras.layers.Embedding(embed_size_dict[\"task_container_id\"] + 1, d_model)\n",
    "    self.part_emb = tf.keras.layers.Embedding(embed_size_dict[\"part\"] + 2, d_model)\n",
    "    self.prior_question_elapsed_time_emb = tf.keras.layers.Dense(d_model, use_bias=True)\n",
    "    self.prev_answered_emb = tf.keras.layers.Embedding(4, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # adding embeddings and position encoding.\n",
    "    c_emb = self.content_id_emb(x[..., 0])  # (batch_size, input_seq_len, d_model)\n",
    "    t_emb = self.task_container_id_emb(x[..., 1])\n",
    "    prior_time_emb = self.prior_question_elapsed_time_emb(tf.expand_dims(x[..., 2], axis=-1))\n",
    "    pt_emb = self.part_emb(x[..., 3])\n",
    "    pv_emb = self.prev_answered_emb(x[..., 4])\n",
    "    x = c_emb + t_emb + prior_time_emb + pt_emb + pv_emb\n",
    "    \n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask) # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.391675Z",
     "iopub.status.busy": "2020-12-20T09:25:17.390989Z",
     "iopub.status.idle": "2020-12-20T09:25:17.401037Z",
     "shell.execute_reply": "2020-12-20T09:25:17.400322Z"
    },
    "id": "vanS2PyP7Hgo",
    "papermill": {
     "duration": 0.038768,
     "end_time": "2020-12-20T09:25:17.401237",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.362469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerSeq2SeqClassifier(keras.models.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate=0.1):\n",
    "    super(TransformerSeq2SeqClassifier, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, maximum_position_encoding, embed_size_dict, rate)\n",
    "    self.out = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "  def call(self, x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "    encoded = self.encoder(x, mask=look_ahead_mask)\n",
    "\n",
    "    out = self.out(encoded)\n",
    "    return out # [batch_size, input_seq_len, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v2XHNJ77Jet",
    "papermill": {
     "duration": 0.025624,
     "end_time": "2020-12-20T09:25:17.452654",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.427030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Embedding sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.509543Z",
     "iopub.status.busy": "2020-12-20T09:25:17.508858Z",
     "iopub.status.idle": "2020-12-20T09:25:17.512166Z",
     "shell.execute_reply": "2020-12-20T09:25:17.511652Z"
    },
    "id": "0kDeBRYH7Q_8",
    "papermill": {
     "duration": 0.033445,
     "end_time": "2020-12-20T09:25:17.512299",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.478854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = 'gs://kds-f48a9c4d95386273c0ef508e337abd3f874b82a454a6c3d0e035839c'\n",
    "DATA_PATH = \"/kaggle/input/riid-0-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.617031Z",
     "iopub.status.busy": "2020-12-20T09:25:17.616238Z",
     "iopub.status.idle": "2020-12-20T09:25:17.644295Z",
     "shell.execute_reply": "2020-12-20T09:25:17.644837Z"
    },
    "id": "_poqM13u7RQd",
    "outputId": "6f50b5c6-560c-4d34-ad86-ec247470a1ed",
    "papermill": {
     "duration": 0.10632,
     "end_time": "2020-12-20T09:25:17.644980",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.538660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content_id': 32736, 'task_container_id': 9999, 'part': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_sizes = pickle.loads(tf.io.read_file(DATA_PATH + \"/emb_sz.pkl\").numpy())\n",
    "embed_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:17.706230Z",
     "iopub.status.busy": "2020-12-20T09:25:17.705477Z",
     "iopub.status.idle": "2020-12-20T09:25:18.912985Z",
     "shell.execute_reply": "2020-12-20T09:25:18.911906Z"
    },
    "id": "Q-3uU1WM7YDF",
    "outputId": "59c0c7cb-6397-49fb-c849-f5bf98333bfd",
    "papermill": {
     "duration": 1.241042,
     "end_time": "2020-12-20T09:25:18.913171",
     "exception": false,
     "start_time": "2020-12-20T09:25:17.672129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_seq2seq_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  23991808  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  513       \n",
      "=================================================================\n",
      "Total params: 23,992,321\n",
      "Trainable params: 23,992,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TransformerSeq2SeqClassifier(\n",
    "      num_layers=1,\n",
    "      d_model=512,\n",
    "      num_heads=8,\n",
    "      dff=1024,\n",
    "      maximum_position_encoding=128,\n",
    "      embed_size_dict=embed_sizes\n",
    "  )\n",
    "model.build(input_shape=(128, 128, 5)) # input_shape - [batch_size, seq_len, features]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:18.994786Z",
     "iopub.status.busy": "2020-12-20T09:25:18.994041Z",
     "iopub.status.idle": "2020-12-20T09:25:21.878837Z",
     "shell.execute_reply": "2020-12-20T09:25:21.878227Z"
    },
    "id": "za2z4w357kEQ",
    "papermill": {
     "duration": 2.937826,
     "end_time": "2020-12-20T09:25:21.878978",
     "exception": false,
     "start_time": "2020-12-20T09:25:18.941152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/kaggle/input/riid-model-0/best-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9Hmlvi870T4",
    "papermill": {
     "duration": 0.027595,
     "end_time": "2020-12-20T09:25:21.935083",
     "exception": false,
     "start_time": "2020-12-20T09:25:21.907488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuunfOds71fi",
    "papermill": {
     "duration": 0.027096,
     "end_time": "2020-12-20T09:25:21.989540",
     "exception": false,
     "start_time": "2020-12-20T09:25:21.962444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Question df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.052064Z",
     "iopub.status.busy": "2020-12-20T09:25:22.051399Z",
     "iopub.status.idle": "2020-12-20T09:25:22.082741Z",
     "shell.execute_reply": "2020-12-20T09:25:22.082002Z"
    },
    "papermill": {
     "duration": 0.06604,
     "end_time": "2020-12-20T09:25:22.082866",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.016826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"/kaggle/input/riiid-test-answer-prediction/questions.csv\", usecols=[0,3], index_col=\"question_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028467,
     "end_time": "2020-12-20T09:25:22.142093",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.113626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.204467Z",
     "iopub.status.busy": "2020-12-20T09:25:22.203690Z",
     "iopub.status.idle": "2020-12-20T09:25:22.229285Z",
     "shell.execute_reply": "2020-12-20T09:25:22.228540Z"
    },
    "papermill": {
     "duration": 0.058507,
     "end_time": "2020-12-20T09:25:22.229408",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.170901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = riiideducation.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.291689Z",
     "iopub.status.busy": "2020-12-20T09:25:22.290388Z",
     "iopub.status.idle": "2020-12-20T09:25:22.294089Z",
     "shell.execute_reply": "2020-12-20T09:25:22.293554Z"
    },
    "papermill": {
     "duration": 0.036574,
     "end_time": "2020-12-20T09:25:22.294239",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.257665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can only iterate through a result from `env.iter_test()` once\n",
    "# so be careful not to lose it once you start iterating.\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.355776Z",
     "iopub.status.busy": "2020-12-20T09:25:22.355064Z",
     "iopub.status.idle": "2020-12-20T09:25:22.361323Z",
     "shell.execute_reply": "2020-12-20T09:25:22.361832Z"
    },
    "papermill": {
     "duration": 0.038968,
     "end_time": "2020-12-20T09:25:22.362014",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.323046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes_train = {\n",
    "    'row_id': 'int64',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32',\n",
    "    'content_id': 'int16',\n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'user_answer': 'int8',\n",
    "    'answered_correctly': 'int8',\n",
    "    'prior_question_elapsed_time': 'float32',\n",
    "    'prior_question_had_explanation': 'boolean'\n",
    "    }\n",
    "\n",
    "dtypes_questions = {\n",
    "    \"question_id\": \"\",\n",
    "    \"bundle_id\": \"\",\n",
    "    \"correct_answer\": \"\",\n",
    "    \"part\": \"int16\",\n",
    "    \"tags\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.422296Z",
     "iopub.status.busy": "2020-12-20T09:25:22.421562Z",
     "iopub.status.idle": "2020-12-20T09:25:22.425224Z",
     "shell.execute_reply": "2020-12-20T09:25:22.425913Z"
    },
    "papermill": {
     "duration": 0.035687,
     "end_time": "2020-12-20T09:25:22.426076",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.390389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.487070Z",
     "iopub.status.busy": "2020-12-20T09:25:22.486258Z",
     "iopub.status.idle": "2020-12-20T09:25:22.498588Z",
     "shell.execute_reply": "2020-12-20T09:25:22.499147Z"
    },
    "papermill": {
     "duration": 0.044389,
     "end_time": "2020-12-20T09:25:22.499326",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.454937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def pad(a, seq_len, max_seq_len):\n",
    "  s = max_seq_len - seq_len\n",
    "  # making [[0, 0], [s, 0]]\n",
    "  r = tf.stack([s, tf.constant(0)])\n",
    "  t = tf.stack([tf.constant([0, 0]), r])\n",
    "  \n",
    "  return tf.pad(a, t) # ,1 to debug\n",
    "\n",
    "@tf.function\n",
    "def trim(a, seq_len,  max_seq_len):\n",
    "  start = tf.squeeze(tf.random.uniform((1,), maxval=(seq_len-max_seq_len), dtype=tf.int32))\n",
    "  # https://www.quora.com/How-does-tf-slice-work-in-TensorFlow\n",
    "  begin = tf.stack([tf.constant(0), start])\n",
    "  size = tf.stack([tf.shape(a)[0], max_seq_len])\n",
    "  \n",
    "  return tf.slice(a, begin, size) # , start - to debug\n",
    "\n",
    "@tf.function\n",
    "def pad_or_trim(a):\n",
    "  seq_len = tf.shape(a)[-1]\n",
    "  max_seq_len = SEQ_LEN\n",
    "  fn = tf.cond(tf.less_equal(seq_len, max_seq_len), lambda: pad(a, seq_len, max_seq_len), lambda: trim(a, seq_len, max_seq_len))\n",
    "  return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.559708Z",
     "iopub.status.busy": "2020-12-20T09:25:22.559011Z",
     "iopub.status.idle": "2020-12-20T09:25:22.565389Z",
     "shell.execute_reply": "2020-12-20T09:25:22.565942Z"
    },
    "papermill": {
     "duration": 0.038118,
     "end_time": "2020-12-20T09:25:22.566115",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.527997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def split_x_mask(x):\n",
    "  x = tf.transpose(x, (1, 0)) # [seq_len, n_features]\n",
    "  pad_mask = tf.cast(tf.math.reduce_any(tf.math.not_equal(x, 0), axis=-1), dtype=tf.float32)\n",
    "  return x, tf.expand_dims(pad_mask, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029741,
     "end_time": "2020-12-20T09:25:22.624555",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.594814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:22.685115Z",
     "iopub.status.busy": "2020-12-20T09:25:22.684406Z",
     "iopub.status.idle": "2020-12-20T09:25:23.449915Z",
     "shell.execute_reply": "2020-12-20T09:25:23.450595Z"
    },
    "papermill": {
     "duration": 0.797487,
     "end_time": "2020-12-20T09:25:23.450759",
     "exception": false,
     "start_time": "2020-12-20T09:25:22.653272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Total time: 0.734 sec\n"
     ]
    }
   ],
   "source": [
    "prev_test_df = None\n",
    "state_dict = {}\n",
    "start = datetime.now()\n",
    "\n",
    "for test_dfm, sample_pred in iter_test:\n",
    "    \n",
    "    # filtering only questions, removing lectures.\n",
    "    test_dfm = test_dfm[test_dfm.content_type_id == False]\n",
    "    \n",
    "    # we have prev df's answers, so store the prev_test_df in state_dict\n",
    "    if prev_test_df is not None:\n",
    "        try:\n",
    "            prev_test_df['answered_correctly'] = list(filter(lambda x: x !=-1, eval(test_dfm['prior_group_answers_correct'].iloc[0])))\n",
    "            prev_test_df['answered_correctly'] += 1\n",
    "            prev_user_group = prev_test_df.groupby(\"user_id\").apply(\n",
    "                lambda row: row.values[:, 1:] # exclude user_id\n",
    "            )\n",
    "            for user in prev_user_group.index:\n",
    "                if state_dict.get(user, None) is None: # new user, add to the state dict.\n",
    "                    state_dict[user] = prev_user_group[user]\n",
    "                else: # existing user\n",
    "                    state = np.vstack([state_dict[user], prev_user_group[user]]) # append to prev features.\n",
    "                    if state.shape[0] > SEQ_LEN: # we dont need history beyond SEQ_LEN\n",
    "                        state = state[-SEQ_LEN:, :]\n",
    "                    state_dict[user] = state\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    # -- process the current df.\n",
    "    # selecting required cols\n",
    "    test_df = test_dfm[[\"user_id\", \"content_id\",\"task_container_id\",\"prior_question_elapsed_time\"]]\n",
    "    \n",
    "    # join question for feaures\n",
    "    test_df = test_df.join(questions_df, on=\"content_id\")\n",
    "    \n",
    "    # 0 used for padding so increment all indicator cols\n",
    "    indicator_cols = [\"content_id\", \"task_container_id\", \"part\"]\n",
    "    for c in indicator_cols:\n",
    "        test_df[c] = test_df[c] + 1\n",
    "        \n",
    "    # fillna and convert milliseconds to minutes.\n",
    "    test_df['prior_question_elapsed_time'] = test_df[\"prior_question_elapsed_time\"].fillna(0).astype(np.float32) / 60000\n",
    "    \n",
    "    # FIXME: unseen ids - content_id > 32736, 'task_container_id'> 9999, 'part'> 7\n",
    "    test_df.loc[test_df[\"content_id\"] > 32736, \"content_id\"] = 0\n",
    "    test_df.loc[test_df[\"task_container_id\"] > 9999, \"task_container_id\"] = 0\n",
    "    test_df.loc[test_df[\"part\"] > 7, \"part\"] = 0\n",
    "    test_df.fillna(0, inplace=True)\n",
    "    \n",
    "    prev_test_df = test_df.copy()\n",
    "    \n",
    "    # -- make x\n",
    "    max_seq_len = 1\n",
    "    xb = []\n",
    "    for idx, row in test_df.iterrows():\n",
    "        user = row[\"user_id\"]\n",
    "        x = np.zeros((SEQ_LEN, 5))\n",
    "        if state_dict.get(user, None) is None: # new user\n",
    "            row[\"prev_ans\"] = 3\n",
    "            x[-1, :] = row.values[1:] # [1:] - skip user_id\n",
    "        else: # existing user, get prev states and build time series.\n",
    "            try:\n",
    "                prev_state = state_dict[user]\n",
    "                row[\"prev_ans\"] = 3 # this will be rolled to the first pos\n",
    "                curr_state = np.vstack([prev_state, row.values[1:]]) # [1:] - skip user_id\n",
    "\n",
    "                seq_len = curr_state.shape[0]\n",
    "                max_seq_len = max(seq_len, max_seq_len)\n",
    "\n",
    "                x[-seq_len:, :-1] = curr_state[:, :-1] # everything except prev_answer\n",
    "                x[-seq_len:, -1] = np.roll(curr_state[:, -1], shift=1) # rolled answer as prev_answer\n",
    "            except Exception as e: # dont use prev state.\n",
    "                x = np.zeros((SEQ_LEN, 5))\n",
    "                row[\"prev_ans\"] = 3\n",
    "                x[-1, :] = row.values[1:] # [1:] - skip user_id\n",
    "                \n",
    "        xb.append(x)\n",
    "    x = tf.stack(xb, axis=0)[:, -max_seq_len:, :]\n",
    "    \n",
    "    # predict\n",
    "    preds = model(x, training=False)[:, -1, :].numpy().flatten()\n",
    "    # preds = model.predict(x)[:, -1, :].flatten() # batched prediction. could be slower.\n",
    "    \n",
    "    \n",
    "    # submit\n",
    "    test_dfm[\"answered_correctly\"] = preds\n",
    "    env.predict(test_dfm[[\"row_id\", \"answered_correctly\"]])\n",
    "    \n",
    "total_time = datetime.now() - start\n",
    "print(f\"===== Total time: {total_time.total_seconds():.3} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035792,
     "end_time": "2020-12-20T09:25:23.519386",
     "exception": false,
     "start_time": "2020-12-20T09:25:23.483594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T09:25:23.609661Z",
     "iopub.status.busy": "2020-12-20T09:25:23.608464Z",
     "iopub.status.idle": "2020-12-20T09:25:23.612384Z",
     "shell.execute_reply": "2020-12-20T09:25:23.611794Z"
    },
    "papermill": {
     "duration": 0.056335,
     "end_time": "2020-12-20T09:25:23.612512",
     "exception": false,
     "start_time": "2020-12-20T09:25:23.556177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def time(func):\n",
    "#     def wrapped(*args, **kwargs):\n",
    "#         t0 = datetime.now()\n",
    "        \n",
    "#         ret = func(*args, **kwargs)\n",
    "        \n",
    "#         dt = datetime.now() - t0\n",
    "#         print(f\"==> {func.__name__} took {dt.total_seconds():.2} sec\")    \n",
    "#         return ret\n",
    "#     return wrapped\n",
    "\n",
    "# # @time\n",
    "# def preprocess(test_dfm, prev_test_df):\n",
    "    \n",
    "#     # we have prev df's answers, so store the prev_test_df in state_dict\n",
    "#     if prev_test_df is not None:\n",
    "#         prev_test_df['answered_correctly'] = list(filter(lambda x: x !=-1, eval(test_dfm['prior_group_answers_correct'].iloc[0])))\n",
    "#         prev_test_df['answered_correctly'] += 1\n",
    "#         prev_user_group = prev_test_df.groupby(\"user_id\").apply(\n",
    "#             lambda row: row.values[:, 1:] # exclude user_id\n",
    "#         )\n",
    "#         for user in prev_user_group.index:\n",
    "#             if state_dict.get(user, None) is None: # new user, add to the state dict.\n",
    "#                 state_dict[user] = prev_user_group[user]\n",
    "#             else: # existing user\n",
    "#                 state = np.vstack([state_dict[user], prev_user_group[user]]) # append to prev features.\n",
    "#                 if state.shape[0] > SEQ_LEN: # we dont need history beyond SEQ_LEN\n",
    "#                     state = state[-SEQ_LEN:, :]\n",
    "#                 state_dict[user] = state\n",
    "        \n",
    "        \n",
    "#     # -- process the current df.\n",
    "#     # selecting required cols\n",
    "#     test_df = test_dfm[[\"user_id\", \"content_id\",\"task_container_id\",\"prior_question_elapsed_time\"]]\n",
    "    \n",
    "#     # join question for feaures\n",
    "#     test_df = test_df.join(questions_df, on=\"content_id\")\n",
    "    \n",
    "#     # 0 used for padding so increment all indicator cols\n",
    "#     indicator_cols = [\"content_id\", \"task_container_id\", \"part\"]\n",
    "#     for c in indicator_cols:\n",
    "#         test_df[c] = test_df[c] + 1\n",
    "        \n",
    "#     # fillna and convert milliseconds to minutes.\n",
    "#     test_df['prior_question_elapsed_time'] = test_df[\"prior_question_elapsed_time\"].fillna(0).astype(np.float32) / 60000\n",
    "    \n",
    "#     # FIXME: unseen ids - content_id > 32736, 'task_container_id'> 9999, 'part'> 7\n",
    "#     test_df.loc[test_df[\"content_id\"] > 32736, \"content_id\"] = 0\n",
    "#     test_df.loc[test_df[\"task_container_id\"] > 9999, \"task_container_id\"] = 0\n",
    "#     test_df.loc[test_df[\"part\"] > 7, \"part\"] = 0\n",
    "#     test_df.fillna(0, inplace=True)\n",
    "    \n",
    "#     return test_df\n",
    "\n",
    "# # @time\n",
    "# def get_x(test_df):\n",
    "#     max_seq_len = 1\n",
    "#     xb = []\n",
    "#     for idx, row in test_df.iterrows():\n",
    "#         user = row[\"user_id\"]\n",
    "#         x = np.zeros((SEQ_LEN, 5))\n",
    "#         if state_dict.get(user, None) is None: # new user\n",
    "#             row[\"prev_ans\"] = 3\n",
    "#             x[-1, :] = row.values[1:] # [1:] - skip user_id\n",
    "#         else: # existing user, get prev states and build time series.\n",
    "#             prev_state = state_dict[user]\n",
    "#             row[\"prev_ans\"] = 3 # this will be rolled to the first pos\n",
    "#             curr_state = np.vstack([prev_state, row.values[1:]]) # [1:] - skip user_id\n",
    "            \n",
    "#             seq_len = curr_state.shape[0]\n",
    "#             max_seq_len = max(seq_len, max_seq_len)\n",
    "            \n",
    "#             x[-seq_len:, :-1] = curr_state[:, :-1] # everything except prev_answer\n",
    "#             x[-seq_len:, -1] = np.roll(curr_state[:, -1], shift=1) # rolled answer as prev_answer\n",
    "#         xb.append(x)\n",
    "            \n",
    "#     return tf.stack(xb, axis=0)[:, -max_seq_len:, :]\n",
    "\n",
    "# # @time\n",
    "# def predict(x):\n",
    "    \n",
    "#     # predict\n",
    "#     preds = model(x, training=False)[:, -1, :].numpy().flatten()\n",
    "#     # preds = model.predict(x)[:, -1, :].flatten()\n",
    "    \n",
    "#     return preds\n",
    "\n",
    "# start = datetime.now()\n",
    "# # test_dfs = [] # for debug\n",
    "\n",
    "# prev_test_df = None\n",
    "# state_dict = {}\n",
    "\n",
    "# for test_dfm, sample_pred in iter_test:\n",
    "# #     print(\"\\n*\\n*\\n--- iteration ---\")\n",
    "# #     t0 = datetime.now()\n",
    "    \n",
    "#     # filtering only questions, removing lectures.\n",
    "#     test_dfm = test_dfm[test_dfm.content_type_id == False]\n",
    "    \n",
    "#     test_df = preprocess(test_dfm, prev_test_df)\n",
    "# #     test_dfs.append(test_df.copy())\n",
    "    \n",
    "#     prev_test_df = test_df.copy()\n",
    "    \n",
    "#     x = get_x(test_df)\n",
    "    \n",
    "#     final_preds = predict(x)\n",
    "    \n",
    "    \n",
    "#     # submit\n",
    "#     test_dfm[\"answered_correctly\"] = final_preds\n",
    "#     env.predict(test_dfm[[\"row_id\", \"answered_correctly\"]])\n",
    "# #     print(f\"iteration took: {(datetime.now() - t0).total_seconds():.3}s\")\n",
    "    \n",
    "# total_time = datetime.now() - start\n",
    "# print(f\"===== Total time: {total_time.total_seconds():.3} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029618,
     "end_time": "2020-12-20T09:25:23.672903",
     "exception": false,
     "start_time": "2020-12-20T09:25:23.643285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028507,
     "end_time": "2020-12-20T09:25:23.734538",
     "exception": false,
     "start_time": "2020-12-20T09:25:23.706031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 19.264179,
   "end_time": "2020-12-20T09:25:23.878791",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-20T09:25:04.614612",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
