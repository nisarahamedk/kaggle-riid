{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "riid-pytorch-transformers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisarahamedk/kaggle-riid/blob/master/notebooks/riid-pytorch-transformers_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666nJ1-WWJLh"
      },
      "source": [
        "%%capture\n",
        "!pip install gcsfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "18rL3yRXV5BA"
      },
      "source": [
        "import math\n",
        "\n",
        "import gcsfs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epiDJGV6V5BA"
      },
      "source": [
        "### Read the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LunXwcomV5BB"
      },
      "source": [
        "# DATA_PATH = \"/kaggle/input/riiid-test-answer-prediction/\"\n",
        "DATA_PATH = \"gs://kds-e80dfc3d272252bbf34c627d756f891826dab0c19f30ec0fc3ac1979\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "bI0E1uWRV5BB"
      },
      "source": [
        "dtypes_train = {\n",
        "    'row_id': 'int64',\n",
        "    'timestamp': 'int64',\n",
        "    'user_id': 'int32',\n",
        "    'content_id': 'int16',\n",
        "    'content_type_id': 'int8',\n",
        "    'task_container_id': 'int16',\n",
        "    'user_answer': 'int8',\n",
        "    'answered_correctly': 'int8',\n",
        "    'prior_question_elapsed_time': 'float32',\n",
        "    'prior_question_had_explanation': 'boolean'\n",
        "    }\n",
        "\n",
        "dtypes_questions = {\n",
        "    \"question_id\": \"\",\n",
        "    \"bundle_id\": \"\",\n",
        "    \"correct_answer\": \"\",\n",
        "    \"part\": \"\",\n",
        "    \"tags\": \"\",\n",
        "}\n",
        "\n",
        "dtypes_lectures = {\n",
        "    \"lecture_id\": \"\",\n",
        "    \"part\": \"\",\n",
        "    \"tag\": \"\",\n",
        "    \"type_of\": \"\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "EEOz3k6DV5BB",
        "outputId": "26c8df19-581f-4577-ca04-d8cd3957f2bf"
      },
      "source": [
        "train_df = pd.read_csv(DATA_PATH + \"/train.csv\", dtype=dtypes_train, nrows=1e6)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>content_type_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>user_answer</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>prior_question_had_explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>5692</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>56943</td>\n",
              "      <td>115</td>\n",
              "      <td>5716</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>118363</td>\n",
              "      <td>115</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>131167</td>\n",
              "      <td>115</td>\n",
              "      <td>7860</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>137965</td>\n",
              "      <td>115</td>\n",
              "      <td>7922</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  ...  prior_question_had_explanation\n",
              "0       0  ...                            <NA>\n",
              "1       1  ...                           False\n",
              "2       2  ...                           False\n",
              "3       3  ...                           False\n",
              "4       4  ...                           False\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "DyfGayw_V5BC",
        "outputId": "a0f51cb8-a113-47f6-94e1-8d3f60a80480"
      },
      "source": [
        "questions_df = pd.read_csv(DATA_PATH + \"/questions.csv\")\n",
        "questions_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>bundle_id</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>part</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>51 131 162 38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>131 36 81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131 101 162 92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131 149 162 29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>131 5 162 38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id  bundle_id  correct_answer  part            tags\n",
              "0            0          0               0     1   51 131 162 38\n",
              "1            1          1               1     1       131 36 81\n",
              "2            2          2               0     1  131 101 162 92\n",
              "3            3          3               0     1  131 149 162 29\n",
              "4            4          4               3     1    131 5 162 38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "oRPol9iZV5BD",
        "outputId": "d96dbbf7-0662-4f6b-b7f3-0ee227681491"
      },
      "source": [
        "lectures_df = pd.read_csv(DATA_PATH + \"/lectures.csv\")\n",
        "lectures_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lecture_id</th>\n",
              "      <th>tag</th>\n",
              "      <th>part</th>\n",
              "      <th>type_of</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89</td>\n",
              "      <td>159</td>\n",
              "      <td>5</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>45</td>\n",
              "      <td>6</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192</td>\n",
              "      <td>79</td>\n",
              "      <td>5</td>\n",
              "      <td>solving question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>317</td>\n",
              "      <td>156</td>\n",
              "      <td>5</td>\n",
              "      <td>solving question</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lecture_id  tag  part           type_of\n",
              "0          89  159     5           concept\n",
              "1         100   70     1           concept\n",
              "2         185   45     6           concept\n",
              "3         192   79     5  solving question\n",
              "4         317  156     5  solving question"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "33-V3ekrV5BD"
      },
      "source": [
        "# removing lecture rows.\n",
        "train_df = train_df[train_df.answered_correctly != -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "eXZ6uVXmV5BD",
        "outputId": "c54b2150-c37e-462d-bacf-2aa9ad563309"
      },
      "source": [
        "train_df = train_df.join(questions_df, on=\"content_id\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>content_type_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>user_answer</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>prior_question_had_explanation</th>\n",
              "      <th>question_id</th>\n",
              "      <th>bundle_id</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>part</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>5692</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>5692</td>\n",
              "      <td>5692</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>56943</td>\n",
              "      <td>115</td>\n",
              "      <td>5716</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>5716</td>\n",
              "      <td>5716</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>118363</td>\n",
              "      <td>115</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131 149 92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>131167</td>\n",
              "      <td>115</td>\n",
              "      <td>7860</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7860</td>\n",
              "      <td>7860</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131 104 81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>137965</td>\n",
              "      <td>115</td>\n",
              "      <td>7922</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7922</td>\n",
              "      <td>7922</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>131 149 92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  timestamp  user_id  ...  correct_answer  part        tags\n",
              "0       0          0      115  ...               3     5         151\n",
              "1       1      56943      115  ...               2     5         168\n",
              "2       2     118363      115  ...               0     1  131 149 92\n",
              "3       3     131167      115  ...               0     1  131 104 81\n",
              "4       4     137965      115  ...               1     1  131 149 92\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "hBAI5pHMV5BD",
        "outputId": "6f32dc0f-d572-49f1-82c8-da3b724f7e35"
      },
      "source": [
        "drop_cols = [\n",
        "             \"row_id\", \n",
        "             \"timestamp\", \n",
        "             \"content_type_id\", \n",
        "             \"user_answer\", \n",
        "             \"prior_question_had_explanation\", \n",
        "             \"question_id\", \n",
        "             \"bundle_id\", \n",
        "             \"correct_answer\", \n",
        "             \"tags\"\n",
        "             ]\n",
        "train_df = train_df.drop(drop_cols, axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>part</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>115</td>\n",
              "      <td>5692</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>115</td>\n",
              "      <td>5716</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115</td>\n",
              "      <td>7860</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>19000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115</td>\n",
              "      <td>7922</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  content_id  ...  prior_question_elapsed_time  part\n",
              "0      115        5692  ...                          NaN     5\n",
              "1      115        5716  ...                      37000.0     5\n",
              "2      115         128  ...                      55000.0     1\n",
              "3      115        7860  ...                      19000.0     1\n",
              "4      115        7922  ...                      11000.0     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "4-DBlD76V5BD",
        "outputId": "a0da2ee9-cb9a-419f-dedd-e9ed5a39fe0f"
      },
      "source": [
        "# 0 is used for padding, so increment 1\n",
        "indicator_cols = [\"content_id\", \"task_container_id\", \"part\"]\n",
        "for c in indicator_cols:\n",
        "  train_df[c] = train_df[c] + 1\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>part</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>115</td>\n",
              "      <td>5693</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>115</td>\n",
              "      <td>5717</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115</td>\n",
              "      <td>7861</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>19000.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115</td>\n",
              "      <td>7923</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  content_id  ...  prior_question_elapsed_time  part\n",
              "0      115        5693  ...                          NaN     6\n",
              "1      115        5717  ...                      37000.0     6\n",
              "2      115         129  ...                      55000.0     2\n",
              "3      115        7861  ...                      19000.0     2\n",
              "4      115        7923  ...                      11000.0     2\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "j2nEsBzAV5BD",
        "outputId": "fb3d4851-5cf7-4f05-e597-1f4d1414780d"
      },
      "source": [
        "# convert milliseconds to minutes.\n",
        "train_df['prior_question_elapsed_time'] = train_df[\"prior_question_elapsed_time\"].fillna(0).astype(np.float32) / 60000\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>part</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>115</td>\n",
              "      <td>5693</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>115</td>\n",
              "      <td>5717</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115</td>\n",
              "      <td>7861</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.316667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115</td>\n",
              "      <td>7923</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  content_id  ...  prior_question_elapsed_time  part\n",
              "0      115        5693  ...                     0.000000     6\n",
              "1      115        5717  ...                     0.616667     6\n",
              "2      115         129  ...                     0.916667     2\n",
              "3      115        7861  ...                     0.316667     2\n",
              "4      115        7923  ...                     0.183333     2\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAu_YF9mV5BD",
        "outputId": "c3237174-df7d-4433-c499-41a1b67f6868"
      },
      "source": [
        "user_groups = train_df.groupby(\"user_id\")\n",
        "len(user_groups)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tMw6HjyV5BE"
      },
      "source": [
        "### Pytorch Iterable Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7iklS-skV5BE"
      },
      "source": [
        "# just some stuff I ctrl C ctrl V from StackOverflow (with little changes)\n",
        "# [1,2,3,4] --- w = 2 --[[1,2], [2,3], [3,4]] but 2D to 3D\n",
        "def rolling_window(a, w):\n",
        "    s0, s1 = a.strides\n",
        "    m, n = a.shape\n",
        "    return np.lib.stride_tricks.as_strided(\n",
        "        a, \n",
        "        shape=(m-w+1, w, n), \n",
        "        strides=(s0, s0, s1)\n",
        "    )\n",
        "\n",
        "def make_timeseries(x, window_length):\n",
        "  \"\"\"\n",
        "  x - shape (seq_len, features)\n",
        "  \"\"\"\n",
        "  # pad a lot of 0s before so when we create windows, we will have appropriate padding.\n",
        "  x = np.pad(x, ((window_length-1, 0), (0, 0)), constant_values=0) # add padding to the first dimension\n",
        "  \n",
        "  # roll windows \n",
        "  x = rolling_window(x, window_length) # shape will become - (seq_len, window_length, features)\n",
        "\n",
        "  return x\n",
        "\n",
        "def add_features_to_user_df(user_df):\n",
        "\n",
        "  # shifted answered_correctly, SOS 3\n",
        "  user_df[\"answered_correctly\"] = user_df[\"answered_correctly\"].shift(fill_value=2) + 1\n",
        "\n",
        "  return user_df\n",
        "\n",
        "class RiidDataset(IterableDataset):\n",
        "  def __init__(self, user_groups, window_length=128, batch_size=32, n_batches=None):\n",
        "    super().__init__()\n",
        "    self.user_groups = user_groups\n",
        "    self.window_length = window_length\n",
        "    self.batch_size = batch_size\n",
        "    self.__len = None\n",
        "    self.n_batches = n_batches\n",
        "    if n_batches:\n",
        "      self.__len = n_batches\n",
        "\n",
        "  def __len__(self):\n",
        "    if not self.__len:\n",
        "      b = 0\n",
        "      for xb, yb in self:\n",
        "        b += 1\n",
        "      self.__len = b\n",
        "    return self.__len \n",
        "\n",
        "  def __iter__(self):\n",
        "    b = 0\n",
        "    for user_id, user_df in self.user_groups:\n",
        "      user_df = user_df.drop(columns=\"user_id\")\n",
        "      y = user_df[\"answered_correctly\"].to_numpy().copy()\n",
        "      x = add_features_to_user_df(user_df)\n",
        "\n",
        "      x = make_timeseries(x, self.window_length)\n",
        "      x = np.transpose(x, (1, 0, 2)) # reshape to [seq_length, bs, features]\n",
        "      # y = make_timeseries(np.expand_dims(y, axis=1), self.window_length)\n",
        "      for i in range(0, x.shape[1], self.batch_size):\n",
        "          start, end = i, i+self.batch_size\n",
        "          if end > x.shape[1]: # ignoring last incomplete batches, this ignores users with interaction < batchsize, FIX THIS\n",
        "                continue\n",
        "          if self.n_batches and b == self.n_batches:\n",
        "            raise StopIteration\n",
        "          yield x[:, start:end, :], y[start:end]\n",
        "          b += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "obfjDLOvV5BE"
      },
      "source": [
        "riid_ds = RiidDataset(user_groups, window_length=128, batch_size=128, n_batches=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HGtRYSpV5BE",
        "outputId": "49d444e9-dcab-460b-bdad-fc789923ef8e"
      },
      "source": [
        "train_dl = DataLoader(riid_ds)\n",
        "x, y = next(iter(train_dl))\n",
        "x.shape, y.shape, x.dtype, y.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 128, 128, 5]), torch.Size([1, 128]), torch.float64, torch.int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StH8mmtZfw8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110ff695-06bc-4d0d-a458-2aa326f7c039"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "         0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "         1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "         1, 1, 1, 0, 0, 0, 0, 0]], dtype=torch.int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMf4uEkLa5_D",
        "outputId": "36ebd028-6b72-419e-a527-7cbf977f397a"
      },
      "source": [
        "len(train_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0jBSXrKV5BE",
        "outputId": "942a9116-a526-4266-f08b-131cc6a59632"
      },
      "source": [
        "batches = 0\n",
        "max_batch_size = 0\n",
        "max_seq_len = 0\n",
        "for xb, yb in train_dl:\n",
        "    max_batch_size = max(max_batch_size, xb.size(2))\n",
        "    max_seq_len = max(max_seq_len, xb.size(1))\n",
        "    batches += 1\n",
        "    \n",
        "max_batch_size, max_seq_len, batches"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoN04M3zxpyW"
      },
      "source": [
        "##### Padding mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmjVawe-xtDp",
        "outputId": "943c84dc-a46a-4ea8-da1b-b4799f1ad5a3"
      },
      "source": [
        "pad_mask = torch.all(torch.eq(x.squeeze(0), 0), dim=-1).T\n",
        "pad_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AU37Y8V5BE"
      },
      "source": [
        "### Transformer Sequence Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KExRqzLASL7Z"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5x0-pN4SPab"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6fMdaxtaV5BE"
      },
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_tokens_dict, d_model=512, n_heads=8, hidden_dim=1024, n_layers=1, dropout=0):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        # Transformer encoder blocks\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, n_layers)\n",
        "        \n",
        "        # Input embeddings for content_id, task_container_id, answered_correctly, prior_question_elapsed_time, part\n",
        "        self.content_id_emb = nn.Embedding(n_tokens_dict[\"content_id\"], d_model)\n",
        "        self.task_container_id_emb = nn.Embedding(n_tokens_dict[\"task_container_id\"], d_model)\n",
        "        self.answered_correctly_emb = nn.Embedding(n_tokens_dict[\"answered_correctly\"], d_model)\n",
        "        self.part_emb = nn.Embedding(n_tokens_dict[\"part\"], d_model)\n",
        "        # self.prior_question_elapsed_time_emb = nn.Linear(1, d_model, bias=False)\n",
        "        # Positional Encoding\n",
        "        self.pos_enc = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
        "\n",
        "        self.out = nn.Linear(d_model, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.squeeze(0) # TODO: take care of this in data loader, extra batch dim incase of IterableDataset [seq_len, bs, d_model]\n",
        "\n",
        "        # padding mask\n",
        "        src_key_padding_mask =  torch.all(torch.eq(x.squeeze(0), 0), dim=-1).T # shape [bs, seq_len]\n",
        "        \n",
        "        # input embedding\n",
        "        content_id_emb = self.content_id_emb(x[..., 0].long())\n",
        "        task_container_id_emb = self.task_container_id_emb(x[..., 1].long())\n",
        "        answered_correctly_emb = self.answered_correctly_emb(x[..., 2].long())\n",
        "        part_emb = self.part_emb(x[..., 4].long())\n",
        "        # prior_question_elapsed_time_emb = self.prior_question_elapsed_time_emb(x[..., 3].unsqueeze(-1).float())\n",
        "        \n",
        "        # shape [seq_len, bs, d_model]\n",
        "        input_emb = (content_id_emb \n",
        "                     + task_container_id_emb\n",
        "                     + answered_correctly_emb\n",
        "                     + part_emb\n",
        "                     # + prior_question_elapsed_time_emb\n",
        "                     )\n",
        "        input_emb = input_emb * math.sqrt(self.d_model) # needed?\n",
        "\n",
        "        input_emb = self.pos_enc(input_emb) # position encoding\n",
        "        \n",
        "        # transformer blocks\n",
        "        z = self.transformer_encoder(input_emb, src_key_padding_mask=src_key_padding_mask) # shape [seq_len, bs, d_model]\n",
        "        \n",
        "        # global average pooling over the sequence length dimension\n",
        "        x = z.mean(dim=0) # shape [bs, d_model]\n",
        "        \n",
        "        # output layer\n",
        "        out = self.out(x) # shape [bs, 1]\n",
        "        \n",
        "        return torch.sigmoid(out)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9JDMerWV5BE",
        "outputId": "779bce2d-4ac2-4c62-f9c4-797484d6cba3"
      },
      "source": [
        "n_tokens_dict = {\n",
        "    \"content_id\": max(train_df[\"content_id\"]) + 1,\n",
        "    \"task_container_id\": max(train_df[\"task_container_id\"]) + 1,\n",
        "    \"answered_correctly\": 4, # 0-padding, 1-incorrect, 2-correct, 3-fill value\n",
        "    \"part\": max(train_df[\"part\"]) + 1\n",
        "}\n",
        "\n",
        "n_tokens_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answered_correctly': 4,\n",
              " 'content_id': 13524,\n",
              " 'part': 9,\n",
              " 'task_container_id': 7741}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHTIue_qV5BE",
        "outputId": "14d64cde-27ee-4bc9-90c5-ec168e5348df"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1PAb6vVV5BE",
        "outputId": "405d340a-f7e0-4820-ea1d-a0c71bdeaa10"
      },
      "source": [
        "model = TransformerClassifier(n_tokens_dict, n_layers=3).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerClassifier(\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0, inplace=False)\n",
              "        (dropout2): Dropout(p=0, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0, inplace=False)\n",
              "        (dropout2): Dropout(p=0, inplace=False)\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0, inplace=False)\n",
              "        (dropout2): Dropout(p=0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (content_id_emb): Embedding(13524, 512)\n",
              "  (task_container_id_emb): Embedding(7741, 512)\n",
              "  (answered_correctly_emb): Embedding(4, 512)\n",
              "  (part_emb): Embedding(9, 512)\n",
              "  (pos_enc): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKdmvTV5V5BE"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1K_ro8KcV5BE"
      },
      "source": [
        "epochs = 1\n",
        "opt = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=0.01, steps_per_epoch=len(train_dl), epochs=epochs)\n",
        "loss_func = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmWcoCpfO7W4"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/nn_tutorial.html#create-fit-and-get-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBgxEJXK3pqr"
      },
      "source": [
        "##### Visualize Gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSKQw0XH3sL0"
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    '''Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        print(n)\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcA8qWtWOQc1"
      },
      "source": [
        "def loss_batch(model, loss_func, X_batch, y_batch, opt=None):\n",
        "\n",
        "  preds = model(X_batch)\n",
        "  loss = loss_func(preds, y_batch)\n",
        "\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    plot_grad_flow(model.named_parameters())\n",
        "    # nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  return loss.item(), X_batch.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7KKDMSb-V5BF"
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl=None, sched=None):\n",
        "  epoch_losses = []\n",
        "  epoch_lrs = []\n",
        "  for e in range(epochs):\n",
        "    # train\n",
        "    lrs = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    model.train()\n",
        "    train_dl = tqdm(train_dl, position=0, leave=True)\n",
        "    for X_batch, y_batch in train_dl:\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.T.type(torch.FloatTensor).to(device)\n",
        "      train_loss, train_bs = loss_batch(model, loss_func, X_batch, y_batch, opt)\n",
        "      train_losses.append(train_loss)\n",
        "      train_loss_mean = sum(train_losses) / len(train_losses)\n",
        "      lr = opt.param_groups[0][\"lr\"]\n",
        "      lrs.append(lr)\n",
        "      train_dl.set_description(f\"Epoch: {e}, RunningLoss: {train_loss_mean:.3f}, InstantLoss: {train_loss:.3f}, LR: {lr:.6f}\")\n",
        "      if sched:\n",
        "        sched.step()\n",
        "    epoch_losses.append(train_loss_mean)\n",
        "    epoch_lrs.append(lr)\n",
        "    # eval\n",
        "    # model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #   val_losses, val_bss = zip(*[loss_batch(model, loss_func, X_batch, y_batch) for X_batch, y_batch in valid_dl])\n",
        "\n",
        "    # val_loss = np.sum(np.multiply(val_losses, val_bss)) / np.sum(val_bss)\n",
        "    # train_dl.set_description(f\"Epoch: {e}, Loss: {train_loss}, Val Loss: {val_loss}\")\n",
        "\n",
        "  return epoch_losses, epoch_lrs#, val_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0olyMi8vG0XM"
      },
      "source": [
        "# train_losses, lrs = fit(epochs, model, loss_func, opt, train_dl, sched=sched)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUG3qDSMCQHF"
      },
      "source": [
        "def debug_model(model):\n",
        "  ds = RiidDataset(user_groups, window_length=4, batch_size=8, n_batches=1)\n",
        "  train_dl = DataLoader(ds)\n",
        "\n",
        "  model.eval() # no funny business by batchnorm\n",
        "  \n",
        "  # first batch,\n",
        "  X_batch, y_batch = next(iter(train_dl))\n",
        "  X_batch = X_batch.to(\"cuda\")\n",
        "  y_batch = y_batch.T.float().to(\"cuda\")\n",
        "  X_batch.requires_grad = True\n",
        "  print(\"First item in the batch is \\n\")\n",
        "  print(X_batch[0, :, 0, :])\n",
        "\n",
        "  model = TransformerClassifier(n_tokens_dict, n_layers=3).to(\"cuda\")\n",
        "  out = model(X_batch)\n",
        "  loss = loss_func(out[:5], y_batch[0:5]) # loss depends on only the first sequence\n",
        "  loss.backward() # hence gradient should also be only propogated to the first sequence\n",
        "\n",
        "  for n, p in model.named_parameters():\n",
        "    if n == \"content_id_emb.weight\": # only the embeddig weights correposponding to the elements in the first sequene in the batch should have a gradient\n",
        "      print(\"Gradients of Content Embedding..\")\n",
        "      # Expected non-zero gradient check\n",
        "      print((p.grad[5693] != 0).all(), (p.grad[0] != 0).all())\n",
        "      # All other gradients 0 check\n",
        "      print((p.grad[5145] == 0).all())\n",
        "\n",
        "      print(p.grad[5693])\n",
        "      print(p.grad[0])\n",
        "      print(p.grad[5717])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltwfiMBE9n1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b04fe3d-2f7a-474e-c07b-2bc44aa163ef"
      },
      "source": [
        "debug_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First item in the batch is \n",
            "\n",
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.6930e+03, 2.0000e+00, 3.0000e+00, 0.0000e+00, 6.0000e+00]],\n",
            "       device='cuda:0', dtype=torch.float64, grad_fn=<SliceBackward>)\n",
            "Gradients of Content Embedding..\n",
            "tensor(True, device='cuda:0') tensor(True, device='cuda:0')\n",
            "tensor(True, device='cuda:0')\n",
            "tensor([-2.0843e-03,  6.0879e-04,  1.9332e-03,  2.1675e-03, -1.4786e-03,\n",
            "        -2.9718e-03,  1.9447e-03, -6.0440e-04, -2.0974e-03, -9.7667e-04,\n",
            "        -1.7431e-03,  1.4518e-03,  7.0761e-04,  7.2395e-04,  6.7528e-05,\n",
            "        -1.8720e-03, -1.8078e-03,  2.7120e-03,  1.5443e-04, -9.7805e-04,\n",
            "        -3.0377e-04,  2.2112e-03, -1.0390e-03, -2.6539e-04,  5.2716e-04,\n",
            "         2.4888e-03,  2.4032e-04,  1.0327e-03, -2.7160e-03, -1.6608e-03,\n",
            "        -2.2457e-03,  1.2988e-03,  1.8293e-03, -4.2697e-04, -2.1536e-03,\n",
            "         5.1314e-04,  2.8012e-03, -1.8949e-03,  4.1140e-04,  1.3273e-03,\n",
            "        -7.3937e-04,  1.0702e-04,  4.7505e-05, -2.9524e-04,  1.1252e-03,\n",
            "        -5.3663e-04, -6.5747e-04, -1.2916e-04, -2.4807e-03, -4.4273e-04,\n",
            "        -1.0494e-03,  1.1852e-04, -1.0487e-03, -2.6928e-03, -1.8235e-03,\n",
            "        -4.0840e-05,  1.4631e-03,  3.8709e-03, -6.3732e-04,  1.8856e-04,\n",
            "        -6.9536e-04, -1.1578e-03, -2.4705e-03, -3.8889e-05, -1.3638e-03,\n",
            "        -1.9301e-03,  2.1373e-03, -2.1517e-03, -3.3812e-04,  3.8076e-04,\n",
            "         2.2783e-03, -1.4327e-03, -7.4596e-04, -2.3715e-03, -1.5468e-03,\n",
            "         1.1327e-03,  1.3805e-03, -1.3018e-03,  9.4242e-04, -9.3479e-04,\n",
            "         1.0278e-03, -1.0537e-03, -2.7650e-04,  3.2333e-03,  1.4974e-03,\n",
            "        -1.7505e-03, -1.9337e-03, -1.8419e-03, -9.8598e-04,  9.2268e-04,\n",
            "        -2.0168e-03,  1.1451e-03, -1.0158e-03,  1.5941e-04, -4.7765e-04,\n",
            "         5.2585e-04,  2.6056e-03,  3.9310e-04, -4.4622e-05, -3.1608e-03,\n",
            "         2.6796e-03, -3.2328e-04,  2.5023e-03,  5.5506e-04, -2.0928e-03,\n",
            "         1.2995e-03,  1.3776e-05,  1.0026e-03,  4.7783e-04, -3.0374e-03,\n",
            "        -2.7177e-03,  3.4841e-03, -7.5654e-04,  1.7469e-03,  1.3537e-03,\n",
            "        -5.4865e-04,  4.3379e-04, -3.4787e-04,  1.6694e-03,  2.3073e-03,\n",
            "         3.1373e-03, -1.4390e-03,  8.3710e-04, -1.9670e-03, -5.3800e-04,\n",
            "        -1.8204e-03,  2.6011e-03, -1.1246e-03,  3.0710e-04, -1.9796e-03,\n",
            "        -3.0528e-03, -3.6938e-04, -3.9192e-04, -4.7652e-04,  1.8685e-03,\n",
            "        -7.3201e-04, -5.4759e-04,  4.0858e-04, -1.4340e-03,  2.7044e-03,\n",
            "        -4.2021e-04, -7.5471e-04,  1.6078e-03,  5.3946e-04, -2.2803e-03,\n",
            "        -2.0121e-03,  1.9960e-03,  2.2837e-03, -3.9007e-03,  8.1608e-04,\n",
            "         4.8681e-04, -2.2837e-03,  5.7425e-04, -2.5626e-03, -9.3398e-04,\n",
            "        -9.9201e-05,  8.2597e-04, -1.8715e-03,  1.6743e-03,  8.3633e-04,\n",
            "        -8.5109e-04,  1.6880e-03,  1.8402e-03,  1.1773e-03,  6.9821e-04,\n",
            "         1.0416e-03, -1.7887e-03,  4.2522e-04, -2.2372e-03, -1.7909e-05,\n",
            "        -2.6248e-03,  9.7211e-04, -1.9385e-03, -3.5004e-04, -3.4219e-03,\n",
            "        -2.1468e-04,  7.0910e-04, -2.4053e-03, -1.3788e-03, -1.2314e-03,\n",
            "        -2.1206e-03,  2.9007e-03,  1.2564e-03,  2.3252e-03, -3.2558e-03,\n",
            "         6.3445e-04,  1.7707e-03, -2.7785e-03, -4.1155e-03,  3.2069e-04,\n",
            "        -5.7137e-04, -7.1247e-05, -3.5460e-04,  1.0306e-03,  6.9882e-04,\n",
            "        -7.8713e-04,  2.7509e-04,  4.1880e-03, -3.6769e-03,  8.4666e-05,\n",
            "         3.5137e-03,  5.9558e-04,  1.3399e-03, -1.4145e-03,  1.2907e-04,\n",
            "        -1.2197e-03, -9.6313e-04, -2.7936e-04, -4.3983e-03, -2.7425e-03,\n",
            "         1.9649e-03, -1.3504e-03,  7.1665e-04, -1.4416e-03,  1.0128e-03,\n",
            "        -1.8348e-03, -1.1199e-03, -1.6905e-03,  2.3796e-04,  1.4231e-03,\n",
            "         7.6695e-04,  7.5506e-04, -7.8717e-04,  1.8420e-04, -3.0360e-03,\n",
            "         1.0664e-03,  6.0775e-04,  2.9758e-03,  1.8454e-03, -7.2620e-04,\n",
            "        -4.3254e-03, -5.8654e-04,  3.3308e-03, -1.5019e-04, -1.4063e-03,\n",
            "        -1.8019e-03, -1.3003e-03, -2.5313e-03, -1.9425e-03, -8.1146e-04,\n",
            "        -9.5210e-04,  3.8847e-04, -8.6101e-04,  1.0999e-03,  4.3130e-04,\n",
            "         2.0334e-03,  1.6308e-03,  4.5870e-04,  1.4066e-03, -2.4970e-03,\n",
            "        -2.2975e-03, -3.3875e-04,  2.0196e-03, -9.6133e-04,  1.9713e-03,\n",
            "         1.2588e-03,  3.2023e-03, -1.9362e-03,  2.8579e-04,  7.4596e-04,\n",
            "         3.1166e-03,  2.6013e-03, -1.7880e-03,  1.9760e-03, -6.5122e-04,\n",
            "        -4.7931e-04,  2.4905e-04,  3.5968e-04, -3.0214e-03,  5.2684e-04,\n",
            "        -1.6861e-04, -2.9741e-03, -1.0128e-03, -6.5195e-04, -8.3078e-04,\n",
            "         2.2040e-03,  3.0952e-04, -4.1813e-05, -1.2525e-03,  2.2368e-03,\n",
            "        -2.1434e-03, -5.2362e-04,  2.8764e-03, -6.8668e-04, -7.7271e-04,\n",
            "         4.7797e-03,  2.7955e-04, -6.9948e-05,  7.3343e-04, -2.4151e-03,\n",
            "        -4.5174e-04,  5.2383e-03,  2.5270e-03,  3.1771e-04,  1.5407e-03,\n",
            "         1.0436e-03, -9.6840e-04,  3.6803e-03,  1.3932e-03, -3.0012e-03,\n",
            "        -1.1320e-03, -7.1412e-04, -3.9215e-04, -1.6700e-04, -8.0269e-04,\n",
            "         1.8317e-03, -4.8105e-04, -5.3619e-03,  1.5673e-03, -8.3803e-04,\n",
            "         1.2063e-03,  2.0315e-03,  2.7760e-03,  5.8970e-04,  3.7355e-04,\n",
            "         9.8935e-04, -4.7957e-04,  2.9185e-03,  2.1018e-03,  3.7814e-03,\n",
            "         3.7016e-03,  9.6002e-04, -4.9312e-05, -5.6537e-05,  2.4998e-04,\n",
            "         2.4736e-03, -3.9760e-04, -1.8323e-04,  7.0664e-04,  1.3038e-03,\n",
            "        -2.4300e-03, -1.1035e-03, -2.9076e-03, -9.9781e-04, -6.7047e-04,\n",
            "         7.2946e-04,  1.3407e-03, -9.8506e-04,  1.6964e-03,  4.8257e-03,\n",
            "        -7.9367e-04,  7.3919e-04,  6.7796e-04, -2.1307e-03,  6.8425e-04,\n",
            "        -1.9808e-03,  2.2897e-03,  1.0754e-03, -1.6669e-03,  3.6973e-04,\n",
            "        -1.7237e-03, -3.6324e-03, -1.0148e-03, -8.2133e-04, -5.6075e-04,\n",
            "         3.0216e-04, -1.3653e-03, -1.1522e-03,  1.0061e-03,  1.0790e-03,\n",
            "        -2.3622e-04,  6.8851e-04, -7.6406e-04,  1.6272e-03, -1.1332e-03,\n",
            "         1.6161e-03,  2.4724e-03,  5.9191e-04, -1.2583e-04,  1.6437e-03,\n",
            "        -5.5820e-04,  1.0746e-03,  2.6433e-03,  4.6395e-04, -8.7907e-04,\n",
            "        -7.8520e-04,  4.2219e-04, -5.6023e-03,  1.1942e-03,  1.4036e-04,\n",
            "         1.7295e-04, -1.5173e-03,  1.6413e-03,  2.5264e-03,  3.5745e-04,\n",
            "        -8.5078e-04,  1.2976e-03, -1.5039e-03, -1.0083e-03,  1.0558e-03,\n",
            "        -5.2123e-04, -1.3458e-03,  1.2639e-03, -1.1325e-03, -1.2074e-03,\n",
            "        -1.3685e-03,  3.3243e-03, -2.6959e-04,  1.3919e-03, -1.7016e-03,\n",
            "        -3.6378e-03, -2.9694e-04, -4.2387e-04, -1.1589e-03, -2.3231e-03,\n",
            "        -9.0497e-04,  1.0975e-03,  7.3202e-04, -5.2873e-04, -1.2975e-03,\n",
            "        -5.5011e-04,  1.7228e-03, -3.2726e-04,  3.1895e-03, -2.7536e-03,\n",
            "        -5.6527e-05,  7.4291e-04, -4.5553e-04, -7.9179e-04, -1.5244e-03,\n",
            "        -1.5753e-03, -2.4918e-03, -2.7078e-04,  3.2623e-03,  1.1762e-03,\n",
            "        -9.8773e-04,  6.1768e-04,  2.8283e-05, -1.0702e-03,  2.1498e-03,\n",
            "         5.7089e-04, -1.5185e-03,  9.3306e-05, -1.8535e-03, -1.9929e-03,\n",
            "        -3.1988e-03,  3.0364e-03, -4.0993e-03, -3.7976e-04,  4.5355e-04,\n",
            "         1.0144e-03,  1.4829e-03, -3.3683e-03,  2.9777e-03,  1.1640e-03,\n",
            "        -1.5565e-03, -1.2438e-03,  1.1556e-05,  8.2249e-04, -1.4619e-04,\n",
            "        -2.2394e-03,  5.6857e-03, -2.0940e-04, -1.1613e-04,  1.0635e-03,\n",
            "         2.0381e-03, -1.4184e-03,  2.0749e-03,  1.8402e-03,  3.1258e-04,\n",
            "         9.7588e-04,  1.9598e-03,  8.7004e-05, -1.6984e-03, -1.1713e-03,\n",
            "         8.7444e-05,  6.0190e-04,  4.0970e-03,  1.1135e-03,  1.5689e-03,\n",
            "         1.4631e-04, -3.5147e-03, -2.8123e-03,  1.9339e-03,  1.7835e-04,\n",
            "        -1.0974e-03,  1.4684e-03,  2.0141e-03, -5.3047e-04,  2.8969e-04,\n",
            "         1.3852e-03, -1.6782e-03,  8.0231e-05, -9.2405e-04,  3.2765e-03,\n",
            "        -2.3779e-03,  2.2525e-03,  1.7811e-03, -1.2604e-03, -4.2757e-03,\n",
            "         2.7967e-03, -4.3894e-04,  3.0757e-03, -2.0523e-03, -1.5323e-04,\n",
            "        -1.4146e-03, -1.0872e-03, -2.0291e-03,  1.1149e-03, -2.1246e-03,\n",
            "        -8.3319e-04, -1.3115e-03,  9.8157e-06,  5.4101e-04, -2.2941e-04,\n",
            "        -3.5275e-04,  1.5974e-03, -1.7352e-04, -1.9061e-04,  1.5606e-03,\n",
            "        -3.2017e-03,  2.5936e-03], device='cuda:0')\n",
            "tensor([-3.4882e-04,  2.4820e-06, -1.1417e-03,  9.2674e-04, -3.3371e-04,\n",
            "        -1.3945e-03,  5.9106e-04,  4.1740e-05,  3.6268e-04,  3.2371e-04,\n",
            "         6.1225e-04,  1.3398e-03,  5.7749e-04, -9.3421e-05, -2.7626e-04,\n",
            "         1.2769e-03, -2.8027e-03,  1.6314e-03, -8.2452e-05, -3.0500e-04,\n",
            "         2.1037e-04, -3.1859e-04, -3.5489e-04,  1.4988e-03, -1.1244e-03,\n",
            "        -1.5237e-03, -2.0419e-03,  2.6175e-04,  2.0245e-04,  7.4703e-04,\n",
            "         1.4351e-04,  1.3957e-03,  2.0088e-04,  8.5498e-04,  6.8887e-04,\n",
            "        -1.7698e-05,  2.0157e-04, -5.5552e-04,  5.4350e-04,  1.0282e-03,\n",
            "         6.3841e-04, -3.8536e-04,  1.2384e-03, -4.6153e-04, -1.2296e-03,\n",
            "        -8.0099e-04,  1.1521e-03, -8.4770e-04, -2.3832e-04, -3.5967e-04,\n",
            "         3.1990e-05, -1.1091e-03, -1.5287e-04, -4.2784e-05, -1.1260e-03,\n",
            "         1.8357e-03, -7.9845e-04,  6.3080e-04,  9.5845e-04,  1.0262e-03,\n",
            "         1.6233e-03, -8.1426e-04, -6.5083e-04,  5.4698e-04,  1.0947e-03,\n",
            "         1.2988e-03,  1.1026e-03, -1.8640e-03, -1.0375e-03, -7.4991e-04,\n",
            "        -6.8452e-04,  1.2050e-03, -2.3603e-04, -1.2821e-03, -1.2891e-03,\n",
            "        -1.1372e-03, -1.2008e-04,  5.1440e-04, -8.8586e-04,  1.6748e-03,\n",
            "         4.9950e-05,  1.2390e-03, -3.7785e-04,  9.2448e-04,  3.8690e-04,\n",
            "         1.7499e-04,  1.0191e-03, -4.2224e-04, -1.0720e-03,  3.5471e-04,\n",
            "        -5.5153e-04, -1.6890e-03,  6.3518e-04,  5.2544e-04, -6.8992e-04,\n",
            "         2.9320e-04,  1.3312e-03, -3.3811e-04,  5.8968e-04, -7.1249e-04,\n",
            "         1.1212e-04,  9.3906e-04, -2.5389e-04,  3.9062e-04, -3.7757e-04,\n",
            "         9.1103e-04,  1.9027e-04, -2.7274e-04, -9.9541e-04, -2.1584e-03,\n",
            "         9.0363e-04,  1.1157e-03,  1.1117e-03,  1.2881e-03,  3.3557e-04,\n",
            "         5.6239e-04,  4.7705e-04,  4.2368e-04, -3.4184e-04,  1.1732e-03,\n",
            "        -6.5977e-04, -1.4617e-03,  1.0614e-03,  5.9857e-04,  2.1558e-04,\n",
            "        -7.6484e-04,  7.7549e-04,  1.8837e-04, -3.9512e-04,  2.4008e-04,\n",
            "        -3.6310e-05,  8.2407e-04, -1.5140e-04,  4.3805e-04,  3.1844e-04,\n",
            "        -1.7578e-03,  1.6887e-03,  2.7848e-04, -4.1450e-04, -8.2013e-05,\n",
            "         1.8911e-04, -1.5950e-03,  1.1950e-06,  4.3839e-04,  2.4801e-04,\n",
            "         7.4030e-04, -8.1299e-04,  1.3842e-03, -6.8743e-04, -1.5299e-03,\n",
            "         6.8146e-04, -1.4409e-03, -2.9556e-04, -5.9468e-04, -6.2075e-05,\n",
            "         1.2680e-03, -1.0839e-03, -1.4964e-03, -1.1260e-03,  3.2991e-04,\n",
            "        -1.1728e-04,  2.8430e-03,  3.2342e-04,  1.2460e-03,  2.5219e-04,\n",
            "         2.1620e-03, -7.8277e-05, -2.9670e-04, -7.2883e-04,  6.8706e-04,\n",
            "        -7.1742e-04,  8.2326e-04, -1.3824e-03,  7.0521e-05, -6.1804e-04,\n",
            "        -6.3708e-04,  1.0113e-03,  8.1741e-04, -7.4213e-04, -5.1608e-04,\n",
            "         2.5055e-03, -3.1496e-04,  2.2998e-03,  5.0260e-04,  4.9504e-04,\n",
            "        -2.1758e-03, -1.3649e-03, -7.4892e-04, -1.9535e-03,  4.0499e-04,\n",
            "        -5.9988e-04,  1.1418e-03,  8.6819e-04,  7.7541e-04, -9.8672e-04,\n",
            "         1.7743e-03,  1.4285e-06,  6.4259e-04, -6.8757e-04,  7.8541e-04,\n",
            "         3.8433e-04, -3.3617e-04,  1.1342e-03,  5.4779e-04, -1.2106e-03,\n",
            "         5.1723e-04, -2.4234e-03,  8.6303e-04, -6.1098e-04, -1.9720e-03,\n",
            "         3.8674e-04, -1.4705e-03, -4.8197e-04, -9.8062e-04, -5.9192e-04,\n",
            "        -9.7145e-04, -8.4769e-04, -1.2241e-03, -4.4149e-04, -5.8709e-04,\n",
            "         1.6031e-04, -2.4344e-04,  1.0637e-04, -1.5062e-03, -2.2570e-03,\n",
            "         7.9067e-04,  1.6096e-03,  9.4578e-04,  7.0133e-04,  9.5730e-04,\n",
            "        -5.0500e-04, -1.0950e-03, -1.3135e-05, -8.5733e-04, -5.1144e-04,\n",
            "         1.2879e-03,  1.1601e-03, -8.3280e-04, -9.1709e-04,  5.7832e-04,\n",
            "        -1.0984e-03,  5.0066e-05, -7.8324e-04, -1.2600e-03,  8.5372e-04,\n",
            "         3.3225e-04,  1.1407e-03, -6.7417e-04,  1.2328e-03,  1.1763e-04,\n",
            "        -8.7503e-04, -1.5365e-03,  7.3413e-04,  2.0271e-03,  1.2001e-03,\n",
            "        -8.5650e-04, -5.5803e-04, -1.7474e-03, -1.1666e-04,  1.7922e-06,\n",
            "         5.3361e-04,  1.4732e-03, -7.6078e-04,  6.6173e-04, -9.7979e-04,\n",
            "        -8.3377e-04, -6.1941e-05,  7.8274e-04,  3.5991e-05,  1.4987e-04,\n",
            "        -1.0412e-04, -1.4782e-03,  9.5193e-04,  1.4319e-03,  1.7318e-03,\n",
            "         1.0538e-03,  3.6094e-04, -2.3231e-05, -8.2343e-04,  2.6883e-03,\n",
            "        -2.1366e-03, -9.7018e-04,  1.2378e-03, -7.7513e-04, -5.3791e-05,\n",
            "         1.8303e-03,  1.4152e-03, -1.8268e-03, -7.0299e-04, -9.4720e-04,\n",
            "        -2.0472e-03,  1.3912e-03,  1.0886e-03, -2.1124e-03,  3.7358e-04,\n",
            "        -5.8326e-04, -1.8624e-03, -3.9393e-04,  6.3632e-04,  1.6779e-06,\n",
            "        -6.9434e-05,  1.5140e-03, -1.2412e-03, -7.7255e-04, -5.1771e-04,\n",
            "         4.6717e-04, -5.1964e-04, -4.0943e-04,  1.0221e-03, -1.9935e-03,\n",
            "         2.2423e-04,  8.4343e-04,  7.6747e-04,  2.4974e-04, -1.3395e-03,\n",
            "         1.9939e-03, -1.5626e-04,  1.8343e-03,  2.8696e-04,  1.0369e-03,\n",
            "        -8.5926e-05,  1.6014e-03,  6.7305e-04, -8.4109e-04,  2.3013e-04,\n",
            "        -1.2114e-03,  4.4225e-04, -1.8493e-03,  1.7528e-04, -3.9895e-04,\n",
            "        -6.5798e-04,  1.1281e-03,  2.7939e-04, -1.0071e-04,  1.4077e-03,\n",
            "        -6.5671e-05,  1.9643e-04,  3.5857e-04,  1.9054e-04,  1.7507e-03,\n",
            "        -1.4901e-03, -1.9926e-03, -1.3441e-03,  9.9646e-04, -5.1198e-04,\n",
            "        -7.5367e-04,  3.0223e-04,  4.8448e-04,  1.1286e-04,  1.0208e-03,\n",
            "         2.0689e-03, -6.7350e-04, -8.3745e-05, -8.1207e-04,  1.1812e-03,\n",
            "        -3.9513e-05, -8.0920e-04, -1.2348e-03,  3.4942e-04, -2.3335e-04,\n",
            "        -1.5477e-03, -4.6876e-04,  1.7638e-03, -6.1059e-04, -3.3474e-04,\n",
            "         5.0941e-04,  3.9904e-04,  3.9417e-04, -1.8222e-04,  1.2348e-03,\n",
            "        -5.1299e-04, -3.2908e-04,  1.9028e-05, -6.0001e-04, -1.1823e-03,\n",
            "         6.0162e-04,  8.0537e-04, -1.1125e-03,  1.0983e-03, -3.9816e-04,\n",
            "        -1.5083e-03, -9.8068e-04, -1.0789e-03,  2.4966e-04,  1.7520e-04,\n",
            "        -4.9409e-04, -1.1063e-04, -1.4981e-03, -1.1129e-03,  5.9246e-04,\n",
            "         2.5714e-03, -6.6127e-04,  3.1007e-04, -8.2793e-05,  5.3350e-04,\n",
            "        -8.3767e-04,  2.3676e-03, -5.1171e-04,  7.0484e-04, -7.7028e-04,\n",
            "        -1.2669e-04, -4.2689e-04,  9.0818e-04, -3.3098e-04, -4.9462e-04,\n",
            "         8.6206e-04,  2.2674e-03,  7.3193e-04,  1.3168e-03, -1.0608e-03,\n",
            "         4.0314e-04, -9.2703e-04, -9.7827e-04,  9.8323e-04, -1.4099e-03,\n",
            "        -7.9225e-05,  4.6906e-04, -3.2168e-04,  9.7399e-04, -9.0513e-04,\n",
            "         3.7826e-06, -2.9878e-04,  1.0939e-03,  7.1405e-04, -1.9745e-04,\n",
            "         8.8975e-04,  2.0203e-04, -9.4872e-04, -1.4601e-03,  5.1550e-04,\n",
            "        -1.2089e-03, -4.9045e-04, -2.1146e-04,  8.8448e-04, -1.0126e-03,\n",
            "         6.4537e-04,  5.5227e-04,  3.8675e-04, -7.8460e-04, -1.6847e-03,\n",
            "        -3.9980e-04, -4.9147e-04, -2.5315e-03, -1.3010e-04,  4.5112e-04,\n",
            "        -1.6230e-04, -5.4468e-04,  1.8207e-04, -1.3540e-03,  5.3219e-04,\n",
            "         1.8609e-03,  1.4120e-03,  4.4949e-04, -3.8286e-04, -2.2528e-03,\n",
            "         1.0454e-03, -1.0376e-03,  1.9531e-04,  1.0576e-04, -1.0373e-03,\n",
            "         1.5912e-03, -4.0345e-04, -2.0152e-03, -4.8119e-04, -1.1319e-03,\n",
            "         1.4073e-03,  7.5888e-04,  1.8716e-03, -7.5361e-04,  1.0193e-03,\n",
            "        -4.7882e-04, -1.1637e-03, -7.1323e-04, -8.5636e-04, -1.7597e-04,\n",
            "         6.7778e-04,  7.5518e-04,  1.4591e-03,  7.5593e-04,  9.7582e-04,\n",
            "        -4.1524e-04, -1.8367e-04,  1.3641e-03,  5.1664e-04, -4.9470e-04,\n",
            "         2.6208e-04,  9.9148e-04,  4.9031e-04,  1.5281e-03,  5.6140e-04,\n",
            "         8.8730e-04, -5.5588e-04, -8.0207e-04, -4.8829e-04, -4.6955e-04,\n",
            "        -2.5097e-03, -1.9152e-04,  1.1330e-03,  8.1370e-04, -1.2066e-03,\n",
            "        -2.7284e-04, -1.0731e-04, -4.1337e-04,  5.6615e-04, -1.6218e-03,\n",
            "        -4.5264e-05, -5.4148e-04,  8.4374e-04, -8.6516e-04,  3.4024e-04,\n",
            "         4.5657e-04,  2.1625e-03], device='cuda:0')\n",
            "tensor([-1.2401e-03,  5.9525e-04,  1.4932e-03,  1.3410e-03, -9.8896e-05,\n",
            "        -1.9285e-03,  1.3257e-03, -4.4337e-04, -5.0554e-04,  7.6139e-04,\n",
            "        -2.8299e-04,  5.0329e-04,  6.2723e-04,  2.5754e-04, -1.2157e-03,\n",
            "        -1.2709e-04, -1.1262e-03,  1.3220e-03,  3.4486e-04, -7.7718e-04,\n",
            "         2.9124e-05,  1.0540e-03, -1.9023e-03,  1.4027e-03,  1.2981e-04,\n",
            "        -5.4646e-05, -1.3017e-03,  1.4989e-03, -6.2338e-04,  4.4848e-04,\n",
            "        -1.1254e-03,  1.0225e-03,  1.4814e-03,  8.3796e-04, -1.4919e-03,\n",
            "         1.0083e-03,  1.2510e-03, -2.2289e-03,  5.8578e-04,  7.5786e-04,\n",
            "         2.9410e-04,  6.8718e-04, -3.4916e-05, -2.1230e-04,  1.6239e-03,\n",
            "        -1.5221e-03, -3.3336e-04, -4.9454e-04, -1.2753e-03, -4.8961e-04,\n",
            "        -6.8470e-04, -6.2418e-04, -7.6394e-04, -8.1437e-04, -6.6050e-04,\n",
            "         7.5579e-04,  7.6348e-04,  1.6328e-03, -3.5418e-04,  4.4937e-05,\n",
            "        -4.5650e-04, -7.0612e-04, -1.4459e-03,  1.1684e-03, -6.0625e-04,\n",
            "        -7.4514e-04,  1.5765e-03, -1.7330e-03, -1.6852e-04,  4.6436e-04,\n",
            "         9.1254e-04, -3.1420e-04, -2.5130e-04, -1.8707e-03, -5.1024e-04,\n",
            "        -8.9828e-05,  6.3339e-04,  3.2546e-05,  2.8335e-04,  6.2633e-05,\n",
            "         7.1161e-04,  4.2038e-04, -7.3592e-04,  2.1631e-03,  2.4179e-03,\n",
            "        -2.4885e-04, -5.6056e-04, -7.1833e-04,  1.6657e-05,  4.6095e-04,\n",
            "        -1.2295e-03,  3.3908e-05,  1.9909e-04,  3.4515e-04, -4.3585e-04,\n",
            "         2.4582e-04,  1.6329e-03,  4.2289e-04,  1.1470e-03, -1.1860e-03,\n",
            "         1.7049e-03, -5.2917e-04,  1.1115e-03,  7.4334e-04, -8.7135e-04,\n",
            "         5.2469e-04, -1.5841e-04,  4.4868e-04, -1.3077e-05, -1.9761e-03,\n",
            "        -2.0194e-03,  2.2899e-03, -2.1050e-04,  1.8028e-03,  1.6232e-03,\n",
            "         5.2372e-04,  7.1926e-04, -4.5731e-04,  6.8386e-04,  1.2896e-03,\n",
            "         1.7581e-03, -9.6822e-04,  9.9295e-04, -4.7401e-04,  7.5581e-04,\n",
            "        -1.3262e-03,  1.3515e-03, -2.2328e-04,  5.6562e-05, -1.6991e-03,\n",
            "        -1.8512e-03,  6.9413e-05, -5.1691e-04, -1.1492e-03,  4.4694e-04,\n",
            "        -9.9178e-04,  9.9217e-05, -8.5274e-04, -1.0997e-03,  1.9097e-03,\n",
            "         4.0551e-04, -1.9425e-03,  1.3661e-03,  1.9650e-04, -7.1364e-04,\n",
            "        -4.7316e-04,  8.3584e-04,  1.5262e-03, -1.9709e-03, -2.3990e-04,\n",
            "         6.9810e-04, -1.7174e-03, -5.3487e-04, -2.3196e-03, -2.9027e-04,\n",
            "        -1.1168e-04,  3.0710e-04, -8.3808e-04,  1.0667e-03,  7.3793e-04,\n",
            "         2.7617e-04,  1.5960e-03,  1.1072e-03,  8.7043e-04,  8.9454e-04,\n",
            "         1.3609e-03, -7.6222e-04, -1.5185e-04, -1.1119e-03,  5.2935e-04,\n",
            "        -2.3733e-03,  1.1959e-03, -3.1651e-04,  3.2935e-04, -1.9203e-03,\n",
            "        -1.0775e-04,  6.7207e-04, -7.4457e-04, -1.2566e-03, -2.0284e-04,\n",
            "        -1.6863e-04,  9.0017e-04,  1.2464e-03,  2.1938e-03, -1.8732e-03,\n",
            "        -1.3123e-03, -3.2068e-04, -1.7277e-03, -2.9913e-03,  8.9288e-04,\n",
            "        -3.4252e-04, -2.3235e-04, -2.4769e-04, -2.7996e-04, -5.9331e-04,\n",
            "         1.0707e-04,  8.1663e-04,  1.8074e-03, -2.7874e-03,  6.5958e-04,\n",
            "         1.4875e-03,  5.6483e-04, -1.6239e-04, -6.1901e-04,  3.5509e-04,\n",
            "         7.9424e-05, -1.4489e-03,  6.7699e-04, -1.5590e-03, -1.1251e-03,\n",
            "         1.1641e-03, -1.3666e-03,  2.8480e-04, -6.9868e-04,  1.1961e-03,\n",
            "        -1.3085e-03, -1.8686e-03, -1.6366e-03,  4.2112e-04,  9.1347e-04,\n",
            "         4.2208e-04,  5.0850e-05, -6.6317e-04,  1.8889e-04, -2.2133e-03,\n",
            "         5.2742e-04,  5.1964e-04,  2.3124e-03,  9.2155e-04,  2.7490e-05,\n",
            "        -2.3320e-03, -2.1638e-04,  1.0682e-03, -4.6743e-04, -8.1278e-04,\n",
            "        -1.4403e-03,  3.3233e-04, -1.3155e-03, -1.4442e-03,  1.5806e-04,\n",
            "        -8.5244e-04, -1.8042e-04, -1.6133e-03, -2.1023e-04,  5.7339e-04,\n",
            "         6.5834e-04,  1.6284e-03, -3.9866e-04,  9.6726e-04, -8.7010e-04,\n",
            "        -1.4946e-03, -2.9979e-04,  1.4924e-03,  3.2292e-04,  1.2441e-03,\n",
            "         7.9704e-04,  1.1060e-03, -9.2883e-04,  8.5125e-04,  4.6558e-04,\n",
            "         2.1660e-03,  2.2061e-03, -9.6316e-04,  1.0810e-03, -2.5309e-04,\n",
            "        -3.6423e-04,  3.5402e-04,  2.6753e-04, -1.7655e-03,  2.9964e-04,\n",
            "         9.2728e-05, -1.0212e-03, -1.7016e-04,  3.2767e-04, -6.5244e-04,\n",
            "         1.9370e-03, -1.6512e-04, -2.5300e-04, -1.0886e-03,  2.4784e-03,\n",
            "        -1.7480e-03,  2.3981e-04,  1.3174e-03, -6.1302e-04, -2.7470e-04,\n",
            "         2.8079e-03,  9.2114e-04, -8.0237e-04,  6.0975e-04, -1.3519e-03,\n",
            "        -1.1240e-03,  2.6328e-03,  1.6631e-03,  2.4764e-05,  4.1229e-04,\n",
            "         2.8290e-05, -9.6191e-04,  1.3248e-03,  4.2552e-04, -1.6672e-03,\n",
            "        -5.7580e-04, -2.3310e-04, -6.5019e-04, -8.8636e-04, -1.1051e-03,\n",
            "         1.1581e-03,  2.3301e-04, -3.1056e-03,  1.9539e-03, -1.0868e-03,\n",
            "         1.2033e-03,  9.2981e-04,  1.4235e-03,  6.8772e-04,  8.2756e-05,\n",
            "         1.6083e-03,  3.2896e-04,  1.6624e-03,  9.6294e-04,  1.8237e-03,\n",
            "         7.9810e-04,  1.0038e-03,  6.7672e-04, -3.1474e-04,  3.3044e-04,\n",
            "         5.4804e-04, -2.2259e-04, -9.5100e-04, -6.3755e-05,  1.1558e-05,\n",
            "        -9.3437e-04, -1.9277e-04, -1.3276e-03, -1.2083e-03,  5.4721e-04,\n",
            "         6.7954e-04,  7.4881e-04,  1.0611e-04,  1.0823e-03,  3.3264e-03,\n",
            "        -1.2422e-03, -5.7326e-04, -5.0139e-04, -6.9107e-04, -1.8577e-05,\n",
            "        -1.9174e-03,  9.8539e-04,  7.4995e-06, -5.6604e-04,  1.0988e-03,\n",
            "        -7.6052e-04, -2.2583e-03, -9.9681e-04, -5.5097e-04, -4.2146e-04,\n",
            "         7.1113e-04, -7.0004e-04, -1.0621e-03,  4.9903e-04,  1.4188e-04,\n",
            "        -2.1185e-04,  3.1008e-04,  7.7659e-04, -7.8904e-05, -2.2409e-04,\n",
            "         1.5192e-03,  2.0935e-03, -3.4113e-05, -6.2443e-04,  1.1044e-03,\n",
            "        -1.2501e-03,  3.5678e-04,  1.0394e-03, -2.1647e-04, -1.1449e-03,\n",
            "        -7.0736e-04, -2.7997e-04, -2.3666e-03,  3.7412e-04,  3.6189e-04,\n",
            "         6.1201e-04, -4.9357e-04,  1.3882e-03,  3.0028e-05,  1.7779e-04,\n",
            "        -7.8897e-04, -2.3109e-04, -1.4301e-03, -2.5493e-04,  1.2319e-03,\n",
            "        -2.6014e-05, -1.4659e-03,  7.6617e-04, -2.7585e-04, -2.7584e-04,\n",
            "        -1.9534e-03,  3.1544e-03, -6.3013e-04,  6.9131e-05, -1.6058e-03,\n",
            "        -2.5728e-03,  6.0035e-04,  7.5556e-04, -7.4747e-04, -6.6162e-04,\n",
            "        -1.9762e-04,  1.5752e-03,  1.1388e-03, -2.4306e-04, -1.2071e-03,\n",
            "        -1.1482e-03, -7.3408e-04, -7.1066e-04,  2.3554e-03, -1.4824e-03,\n",
            "         4.8322e-04,  6.6259e-04, -3.0571e-05, -4.4583e-04, -1.1495e-03,\n",
            "        -1.3150e-03, -1.1060e-03, -5.7426e-04,  1.7655e-03, -3.1288e-05,\n",
            "        -6.2821e-05,  9.7494e-04,  2.8075e-04, -9.2772e-04,  2.0559e-03,\n",
            "        -7.7375e-05, -8.5184e-04,  2.9223e-04, -1.0003e-03, -1.9039e-03,\n",
            "        -1.2542e-03,  1.2682e-03, -2.6571e-03, -7.3805e-04, -1.8234e-04,\n",
            "         6.5712e-04, -7.4203e-05, -1.7091e-03,  1.5545e-03,  1.6365e-03,\n",
            "        -1.8342e-03, -1.2871e-03, -1.1541e-03, -2.5215e-04,  9.5595e-04,\n",
            "        -1.6060e-03,  2.6449e-03,  2.0245e-04, -3.5040e-04,  3.1254e-04,\n",
            "         1.5413e-03, -6.4768e-04,  1.2496e-03,  3.7749e-04,  9.3557e-05,\n",
            "         1.5221e-03,  6.5853e-04, -5.8770e-04, -1.5766e-03, -1.4386e-03,\n",
            "         5.1711e-04,  4.5096e-04,  2.4264e-03,  1.1776e-03,  9.8071e-04,\n",
            "        -8.2297e-04, -1.6396e-03, -1.2325e-03,  1.0080e-03, -5.9503e-04,\n",
            "        -2.2807e-04,  1.3879e-03,  1.3340e-03, -8.1406e-05,  6.4299e-04,\n",
            "         1.0941e-03, -9.6507e-04,  1.4778e-04, -8.1375e-04,  1.0272e-03,\n",
            "        -1.3566e-03,  1.2827e-03,  1.5388e-03, -2.1763e-04, -2.3248e-03,\n",
            "         1.4837e-03, -1.1396e-04,  1.2162e-03, -2.2057e-03,  3.2142e-04,\n",
            "        -1.4602e-03, -9.9346e-05, -1.2665e-03,  8.4600e-04, -1.6428e-03,\n",
            "        -5.9344e-04, -1.0053e-03, -8.6008e-04,  4.8128e-04, -2.1851e-04,\n",
            "         2.8764e-04,  6.5916e-04, -1.2249e-03, -2.2760e-04,  1.4522e-03,\n",
            "        -2.4226e-03,  2.1232e-03], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb8ZxOtfFIYr"
      },
      "source": [
        "plt.ylim(top=1)\n",
        "plt.plot(train_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJXQ30QKFRr"
      },
      "source": [
        "plt.plot(lrs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCP4UnYdGB3_"
      },
      "source": [
        "xb = xb.to(device)\n",
        "preds = model(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2nt08h1SQ8"
      },
      "source": [
        "yb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmKaBcxE1XdV"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyC80r-NUrjV"
      },
      "source": [
        "y_hat = preds.to(\"cpu\").detach().numpy() > 0.5\n",
        "y_hat = y_hat.astype(np.int8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBYitHZhU3DK"
      },
      "source": [
        "y_true = yb.to(\"cpu\").detach().numpy().T\n",
        "y_true.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8in5UADV50R"
      },
      "source": [
        "accuracy_score(y_true, y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDYPPqqzWOmK"
      },
      "source": [
        "precision_score(y_true, y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLgz51aEYUiy"
      },
      "source": [
        "recall_score(y_true, y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjZreOaXYW6k"
      },
      "source": [
        "y_true.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz3BA7xpWaMo"
      },
      "source": [
        "y_hat.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fLoQpxcWeP2"
      },
      "source": [
        "roc_auc_score(y_true, preds.to(\"cpu\").detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reAvhC2SUcaU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}